{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_Detection_Using_Deep_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBFjBQyiQALXd9BjjalqUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/Emotion-Detection-using-Deep-Learning/blob/master/Emotion_Detection_Using_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOnkXJVR-vNa",
        "colab_type": "code",
        "outputId": "b1e77b62-0cea-49f2-d697-2b3cb8b1303f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Select TensorFlow 2.0 environment\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSbkNyrz5xkL",
        "colab_type": "text"
      },
      "source": [
        "You need to get your API key from your Kaggle account to be able to proceed with the following. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYnT4qp-3E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colab imports for setting up Kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67YOp6Y9-7BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up Kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caJiwp3y_Agi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the data\n",
        "# https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34neb1rU_Ek9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip dataset\n",
        "!unzip -qq icml_face_data.csv.zip\n",
        "!unzip -qq test.csv.zip\n",
        "!unzip -qq train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSgtCIaq_iuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General imports\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4fcMaGFAQrN",
        "colab_type": "code",
        "outputId": "27e857f5-219c-45d3-e868-f8286dc93eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load up the training dataset\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I05tBXyaGztD",
        "colab_type": "code",
        "outputId": "57581d01-cb70-4a22-8531-f2668cbc7f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Class distribution\n",
        "train[\"emotion\"].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    7215\n",
              "6    4965\n",
              "4    4830\n",
              "2    4097\n",
              "0    3995\n",
              "5    3171\n",
              "1     436\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oGPWHJuP0pY",
        "colab_type": "text"
      },
      "source": [
        "Class imbalance noticed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tugm4rNZEVpM",
        "colab_type": "code",
        "outputId": "7efe0f29-0333-4f49-c9f5-781236f1b6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load test dataset\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              pixels\n",
              "0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...\n",
              "1  156 184 198 202 204 207 210 212 213 214 215 21...\n",
              "2  69 118 61 60 96 121 103 87 103 88 70 90 115 12...\n",
              "3  205 203 236 157 83 158 120 116 94 86 155 180 2...\n",
              "4  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMRozBIWAd8C",
        "colab_type": "text"
      },
      "source": [
        "Note on the label mapping:\n",
        "\n",
        "(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqzUp-dIAU3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to clean the dataset\n",
        "# Taken from http://bit.ly/37AUk7f\n",
        "def clean_data(dataframe):\n",
        "    image_pixels = np.zeros(shape=(len(dataframe), 48, 48))\n",
        "    labels = np.zeros(shape=(len(dataframe), ))\n",
        "    for (i, row) in tqdm(dataframe.iterrows()):\n",
        "        image = np.fromstring(row[\"pixels\"], dtype=int, sep=' ')\n",
        "        image = image.reshape(48, 48)\n",
        "        image = image.astype(\"float\")/255\n",
        "        \n",
        "        image_pixels[i] = image\n",
        "        labels[i] = row[\"emotion\"]\n",
        "    \n",
        "    return (image_pixels, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtreWITkAoSi",
        "colab_type": "code",
        "outputId": "8af74788-cba2-45b2-f5f4-1a656a409d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Clean the training dataset and verify the shapes\n",
        "(train_pixels, train_labels) = clean_data(train)\n",
        "train_pixels.shape, train_labels.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28709it [00:05, 5174.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28709, 48, 48), (28709,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaZtUxc1IKOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn and other utility imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLtIOejPIkOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encode the labels\n",
        "le = LabelEncoder().fit(train_labels)\n",
        "train_labels = to_categorical(le.transform(train_labels), 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJAZX2B1I1q0",
        "colab_type": "code",
        "outputId": "68c751fe-4ce0-40ea-fa3b-c392829246e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFXCWLEIH2qT",
        "colab_type": "code",
        "outputId": "ca04fbee-f578-4e59-e968-a85d3dc94ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the training data into further partial training and validation data\n",
        "(trainX, valX, trainY, valY) = train_test_split(train_pixels,\n",
        "    train_labels, test_size=0.15, stratify=train_labels, random_state=42)\n",
        "trainX.shape, trainY.shape, valX.shape, valY.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24402, 48, 48), (24402, 7), (4307, 48, 48), (4307, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Liy4gy-xje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a91ecf2d-b37b-4558-d8f6-8133969c632a"
      },
      "source": [
        "# Serialize the data for later reproducibility\n",
        "np.save(\"trainX.npy\", trainX), np.save(\"trainY.npy\", trainY)\n",
        "np.save(\"valX.npy\", valX), np.save(\"valY.npy\", valY)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3M0z8zoL9K8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b439553c-a301-47b0-d6c3-ba89edb917d7"
      },
      "source": [
        "# Load it like this\n",
        "trainX, trainY = np.load(\"trainX.npy\"), np.load(\"trainY.npy\")\n",
        "valX, valY = np.load(\"valX.npy\"), np.load(\"valY.npy\")\n",
        "trainX.shape, trainY.shape, valX.shape, valY.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24402, 48, 48), (24402, 7), (4307, 48, 48), (4307, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-vzxKMHHLLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Account for skew in the labeled data\n",
        "classTotals = trainY.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NktmFLvMMCUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the label mapping\n",
        "LABELS = {\n",
        "    0: \"Angry\", \n",
        "    1: \"Disgust\", \n",
        "    2: \"Fear\",\n",
        "    3: \"Happy\", \n",
        "    4: \"Sad\", \n",
        "    5: \"Surprise\", \n",
        "    6: \"Neutral\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzuhav_kMjm5",
        "colab_type": "code",
        "outputId": "a436667c-366a-40d2-80e7-06765c4ee799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Spot check the dataset\n",
        "train_idx = np.random.choice(len(trainX), 5)\n",
        "for id in train_idx:\n",
        "    plt.imshow(trainX[id].reshape(48, 48), cmap=\"gray\")\n",
        "    plt.xlabel(LABELS[np.argmax(trainY[id])])\n",
        "    plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2de6zdVZXHv6vlUSjQB33QcvuglEdB\nHn0BFSFYChY0FE11KGQGMzj8wYzByARxiBONQ8CYiJoxzhARO8aID0QIOE6AAQkTApQCQl+0FOi7\nl9IHUBRKu+aPc665v+9evWdz7r3nnrq/n6Tp3bv7t3/79/ud1d9Z37vW2ubuEEL89TNooBcghGgN\nMnYhCkHGLkQhyNiFKAQZuxCFIGMXohB6ZexmNt/MVpnZGjO7qa8WJYToe6zZ37Ob2WAALwO4CMAG\nAM8AWOTuy/d3zKBBg/yggw6q9O3bt6/SHjx4cHIcj4ngMYMGpf+PHXzwwZW2mTUcw20A4Hv25z//\nORmzd+/epI+vPTr/IYccUmlH9yMHPj+fG0jv0QcffJA1N9/r6PnwteWcP7pWHhM9Vz5XdF8bzQvE\nz4yvLZqbx7z77rvJmHfeeafSHjJkSDJm5MiRlfZRRx2VjInuY3dee+01bNu2LbwBPR/ZM2cBWOPu\nawHAzO4GsADAfo39oIMOwujRoyt9f/rTnyrtYcOGJcfxmOiG88087LDDkjHjxo2rtNmwojHHHHNM\nMmbPnj2V9ooVK5Ixu3btSvpGjRpVaUf/kUycOLHSjh44f1Cj/7DfeuutSvvoo49Oxhx++OGV9rZt\n25IxkQHu3r270ubnA6Qfyuj8/IxGjBjRcEz0XA899NBKO+c/SL52AHj77beTPv5cRcbG17906dJk\nzBNPPFFpn3rqqcmYz372s5X2JZdckozh+8jPfvbs2ckxXfTma/yxANZ3a2+o9wkh2pDevNmzMLNr\nAVwLNP+VVAjRe3rzZt8IYEK3dke9r4K73+Hus9x9VuQnCSFaQ2/e7M8AOMHMjkPNyK8AcGWjg9jf\nZv83Ejfef//9HucAUl9u7NixyRj2h88///xkzPHHH9/juYHU154/f34y5re//W3St2TJkkp70qRJ\nyZj33nuv0t68eXMyhn3USHvgvs7OzmQM32s+NxALWUOHDu1xPUB6jyJBasKECZX2kUcemYxpRmyL\n1swiWiTGRefia4tETL7WqVOnJmPWrVtXabPuAaQ6Agt2ETn3p4umjd3dPzCzfwLwPwAGA/ixuy9r\ndj4hRP/SK5/d3X8H4Hd9tBYhRD8iJ1qIQuh3NZ5h34l/bxj5IDnBHuyjdnR0JGMuvfTSSpt/pw6k\nfjX/vjo6F/ueALBw4cKkb+vWrZX2m2++mYxpdK6I6HfPTKSFcB/rJ0B8bTkayhFHHFFpjxkzJhnD\nvm4UnMPzRJ8FXnc0D/8mKNJiouMaBbEAqf8faQ/8eXzxxReTMXytOQE8H0b01ptdiEKQsQtRCDJ2\nIQpBxi5EIbRUoHP3JHCfE1+2bNmSHMcCzEknnZSMOeGEEyrtuXPnJmM4aOHJJ59MxrCQctZZZyVj\n+Bq2b9+ejOEECgC4+OKLK+1vfvObyRgWDSOBbPjw4ZX2xo1J4GIStJGT4RcJSzt37kz6+JlFYigL\nrzkiayQ2RUk2DAtk0bXyM8sNRsmZm4mug5/r+vXrkzGcKNXX6M0uRCHI2IUoBBm7EIXQUp990KBB\nSWIB+7acrAKk/viMGTOSMewjRskZL7zwQqUdJaLw+aNAi02bNlXakX++Y8eOpG/y5MmV9plnnpmM\nefXVVyvtDRs2JGPY/40q5fD1R0EtnCzE1wXEacns20fnf/nllyvtKKkjpwgHB5rkVMWJfGaeOzpX\n1MfBN9EYvkdRkg0nD1144YXJmNNOOy3p60v0ZheiEGTsQhSCjF2IQpCxC1EILRfoWNw57rjjKu15\n8+Ylx5144omVdiSIMStXrkz6WMg59ti0PiaLK88880wyJqpCykRZZuPHj6+0o2o6LHZFVVBZtIoC\nb1ikioJBOBgnqlTDwhKQBvVEmWFcmSaah4N6onlYjMzJ8mqm9DgQi2+8xuge8bqjTEX+PESVe3JK\nUvPng+9rT6Xh9WYXohBk7EIUgoxdiEJoqc8+dOhQzJw5s9LHiSZRUA37IeyzAmlFmagSySmnnFJp\nR7utvPTSS5V2FJzDfhIHywCxHrBq1apKe86cOckYvh+vvfZaMob91igYhu9H5A/nBIxMnz496eMg\nkqjiDgc5Rc+M738UjMLXmuOPR9eRU102CiDK8cdz5uGgpmiNnPCVs0ZOFOrp/ujNLkQhyNiFKAQZ\nuxCFIGMXohBaKtANGTIE06ZNq/SxkJO7bzbDZZqj7ZB5++XHHnssGbN8eXXH6ai8MlfKiQIkItGK\n1xSVgOYst2XL0k12WISJAm9YNIzuB68xqlSTQxQwk7P3OwuEOQEzOeWVI5EqZ+6cz17O9k/RvWbB\nNHpmLNpFQh+fn9enoBohhIxdiFKQsQtRCC312c0s9Ge6E/07J55ECQK8tXFUmYW33Fm7dm0yhv3x\nSC8YPXp0pR1VxI38+JxtjDnQhBOFgLSaTVQFhn3CyNfl80f3Prr+Xbt2VdqshQBpMErkD/P5cqrA\nRPOw7x/57NwX3Y9In+G5o2AtDryKroPvWRSsxZpJpA/w9fOaIz//L8fu91+EEH9VyNiFKAQZuxCF\nIGMXohBaXqmmkSgUiRIsyEVjWICJsrxeeeWVSptFEwBYs2ZNpd3Z2ZmM4W2cIjEwOj9nfkXBKJwt\nx0E+QCoAcUARkApJ0RpHjBhRaUdBPlEfi4g8T9QXCUeR0MpwllkkvvGY6Fw5Il4k0OVkonFfVFqb\nzx8JdEx0HSws8jw9bU+lN7sQhSBjF6IQGhq7mf3YzDrN7KVufSPN7CEzW13/O/0eJ4RoK3J89p8A\n+HcA/9Wt7yYAj7j7bWZ2U739lUYTRUE17N9E1TvZv8pJWIh8bfajZ82alYzh5JiouuzXvva1Sjva\nVjjqY/83Cr7gbaNYZwDS6rpTp05NxnAwDle2jYj8SK4kG41rNoGFPwuRz8z3KPK1+dlH8/D5c7aR\nAvK2qOLPbDQ3j+EEsIjoXLlbTUc0fEru/jgA3oB8AYDF9Z8XA7i86RUIIVpCsz77WHfvik/dAiAt\ngC6EaCt6LdB57bvGfpNozexaM1tiZktyNlcQQvQPzRr7VjMbBwD1v1MHuY673+Hus9x9VrPFEYQQ\nvafZoJr7AVwN4Lb63/flHDRo0KAkkIQFh5yqNNH2TyxmRIENHAwSCUv87eMLX/hCMmbYsGGVdiQG\nRoEmfK1RBtXzzz9faUfXcdFFF1XaUXljFoAioY3v9ahRo5Ix0dwc1JQjiEXw3JGoyfNEgSac4RcJ\nW/yZiQKzoutgsS2am4XfaG4m2rKrv8n51dvPATwJ4CQz22Bm16Bm5BeZ2WoA8+ptIUQb0/DN7u6L\n9vNPF/bxWoQQ/Ygi6IQohJZXqmE/LfKTGPZbuVInAEyZMqXS3rlzZzKGg0E46QUAjj/++Er73HPP\nTcasXr260o4SWqIqNOzbcSVZIN1+iqvxRnNHSTd8XyM/MmeenKSSiBx9gjWDqFJOTqIHzxON4c9d\nlIST81lsNtCFPyPRdt3NzPth0JtdiEKQsQtRCDJ2IQpBxi5EIbRcoONAlkalcbuO606UVcRBI9u3\nc+5OWtElClhhASYKmGFxJUdsAdLMp0ceeSQZwyJVVGGG1x3tD58j0OVkdDUrWnFfFCzF1xo910j8\nZPjaouAcFgijYKEoWIsFymjbJn6u0bVyuW8O8IqQQCeEaAoZuxCFIGMXohBk7EIUwoBH0LEIEQlC\nXM4pys5icWf37t3JGI6qi4QtzhabOHFiMob3eouIIs848i4ScubMmVNp5+wHHomILGxFJaE5Oi1a\nT5QZ2EypqEgQy8kW476obBkLa1H0JBM9n6iPP4+RaJYTLcifmShake+rBDohRFPI2IUoBBm7EIXQ\nUp89gv2SRvu3A7H/yf5O5PuzPx6V8+WyzNHe5+zHRvpA5P92dHRU2p/+9KeTMcuWLau0owARDiCK\nAjR4q6mcLaqi4JjIH2dytkSK5mbf9s0330zG8L2NAqG2bdtWaeeU344q93AFIiDVbKLSajl7yOfo\nPPLZhRB9goxdiEKQsQtRCDJ2IQphwAU6FoBy9qSOhAvOcouCL8aNG1dpRwIdZzXllGCKymRF2VEs\nCkXXMWPGjEo7Kp/EQTSR+MUlp3KCQSKhLZqbiQQpFsQioY/Ft0ig4+OigBm+jihTjkuARXv4RSLa\nBRdcUGlz2TIgb++7gShDxejNLkQhyNiFKAQZuxCF0HKfvdFe3pGPzEE0kY/MfmwUDMNEyRnsN0VB\nHOxr5iaQsP8dBcxw0Ea0Zzr70c3qHM364xywFAUVsYYSXStvtRU9D/48RL4/P6Po2Z999tk9nhuI\nNYNdu3ZV2tGz5vsRBYbl7Mfe3+jNLkQhyNiFKAQZuxCFIGMXohBaLtCxwMLCUSTSMDt27Ej6WPzK\nmScScnIysfgaIhFt8+bNSR8H2kRrZLEpErY4YCYS0ZoJmImqp+RkvUUBTLymaG7OxONS3wCwfPny\nSjvKZnzuuecq7WOOOSYZ85GPfKTSzhE1gfT+R9fKx0XVjfiz1uyecb1Bb3YhCkHGLkQhyNiFKIQB\nT4RhXy7yf9mPnTRpUjKGq7VEvu6ECRMq7SgYhKuZRr4VrzHyvaM+9hOjgB0m8uMa6R5RXxTokeOP\n5/iROdWFoorAHEAUVfvle71y5cpkDOss69evT8bk6BzRs+aKwDn++LRp05IxOeeSzy6E6BNk7EIU\ngoxdiEJoaOxmNsHMHjWz5Wa2zMyur/ePNLOHzGx1/e8R/b9cIUSz5Ah0HwC4wd2XmtmRAJ41s4cA\nfB7AI+5+m5ndBOAmAF/paSJ3byiA5WQVRVVgOJAiEp9YyIlEvBw4gCcnqCVaUyRs8bVG96PRFlpA\nKnzmbDcUbb+UIyRF18HCWhTEknM/uPw2l9oG0uCcqGw290Xi7MaNG5M+DuB64403kjEf/ehHK+0z\nzjgjGcM0yv7sDxqe0d03u/vS+s9vA1gB4FgACwAsrg9bDODy/lqkEKL3fKj/XsxsMoDpAJ4CMNbd\nu2JCtwAIi2yZ2bVmtsTMlkR56EKI1pBt7GZ2BIB7AHzJ3StW67XvemElBHe/w91nufusaOcSIURr\nyAqqMbODUTP0n7n7b+rdW81snLtvNrNxANJ9g+O5evz3KNGAfbuomg33Rb4uB7FwoEUuOVsbRbA/\nHv3nx3NHviX77JH/F/nIjdYT3bPIj2ciX5vvbfStjqvA8JZVQHr9UZILB+dEQVd8P9atW5eMiYJx\nuCrslVdemYxZsGBBpR3pI+1AjhpvAO4EsMLdv9Ptn+4HcHX956sB3Nf3yxNC9BU5/wWdC+BvAbxo\nZs/X+/4FwG0Afmlm1wB4HcDn+meJQoi+oKGxu/sTAPb33fvCvl2OEKK/UASdEIXQciWBxSwW1qJK\nJCxARaIR90ViEwtJkdDHAmG0FzwLa5GIlkPOGqOtjPi4SPTMuR85QmN0HBOdn59Z9Fy53PTatWuT\nMVzyOQqo4ky0nDLiHKwDAJ/5zGeSvhtvvLHSjkpC5wq0A43e7EIUgoxdiEKQsQtRCANeXbaZrYwi\nX5t9S94yODpX5GuyzxytJ9pGmcmp1BoFo7CvHVW8yUmi4ACiHN87Ikoo4vPnVMGJAmbYH4+CnPi4\nYcOGJWNYQ8m5P1HwVhSwwz56dD/6u8JMX6E3uxCFIGMXohBk7EIUgoxdiEJoqUDn7onA0UiwA1Jx\nKRKbWJCLhDU+LgrQyMkE40CbKGAkqoLDol0kEvFcUbnpqNw2w/cxuq/cFwlbOUJjsyWp+f7nXFcE\nH5eznujZ5zAQFWb6igN35UKID4WMXYhCkLELUQgydiEKoeUCHUe/cTsShDhiLRLNeJ6cSLwoEo6z\nzCJBhoW1SBDKEfYieK4ogo7nzolyy9mfPTpXlGHI9zES/3LKhHHkXTQPP6MoC5DPFYmBfNzw4cOT\nMZHQyuvOKffVrujNLkQhyNiFKAQZuxCF0HKfnf0i9oFyyhlHlWFyAj3YJ4yytTgTK/Kz2bfNLR3M\n1x75iDx3TinniJwMP773Ob5/RPTMco7jNUWZihz8EvnafB2RX8/3NXr20fk5OCrK3supVNMOmXF6\nswtRCDJ2IQpBxi5EIcjYhSiElgp0+/btSwQPFkVyMpYiQYxFmihbrNHe8EAqCEXZazxPJEZFAhDP\nHYk2OeWjeN059ywKBskRLCNYWIzOz/coEhp5v7WoLNSUKVMqbRZQgTSoJnquzWarbdu2rdKOBLpG\ngWLRcc2Ker0pW603uxCFIGMXohBk7EIUQsuDajiJJCf4I6csMfvxUZIL7xGesz97ztZG0T7r0dzs\nb0baA/u2kWaQk4zBc+cEdUR+dU6Fm6jizpYtWyrtjRs3Njx/zv2IKsyw7hPtBR9t28RE18HnjwKh\nuC+617ymnGcY6QyN9Jme/l1vdiEKQcYuRCHI2IUoBBm7EIXQUoHOzMJqKN2JBBAOkImCFnL2I8/Z\nEyxnrzUW3yJhKyeIIxJTcoQ1Pi5HRIzuB4tEkWgUZYJt3ry50t60aVMyhp9jtGc6Z6dF82zYsKHS\nnjp1ajLmyCOPrLR37dqVjOHrj55PJIbmZCGyYBkJjY2yPZuFr6unoBu92YUoBBm7EIXQ0NjNbIiZ\nPW1mL5jZMjP7Rr3/ODN7yszWmNkvzKzn7+dCiAElx2d/D8Bcd3/HzA4G8ISZ/TeALwO43d3vNrP/\nAHANgB/2NNG+ffuSwIWtW7dW2jlJDG+88UYyJmdfdR4T+ePsD+dUk4n8v8hv5PNHQRx8/mjunESY\nHD+SfdS1a9cmYzhZJSLaM33UqFGVdqSzcMWhSHtgP/4Pf/hDMmbOnDmV9vTp05MxnZ2dlXYUCBVt\nP8X6TFS5iJ9j9Nnj5xjdDz5/M4kwPWlFDd/sXqNLpTm4/scBzAXw63r/YgCXN5pLCDFwZPnsZjbY\nzJ4H0AngIQCvANjp7l3S5AYAx/bPEoUQfUGWsbv7Xnc/E0AHgLMAnJx7AjO71syWmNmSqFCkEKI1\nfCg13t13AngUwBwAw82syxHsABBmOrj7He4+y91nRVU/hRCtoaFAZ2ajAexx951mdhiAiwB8CzWj\nXwjgbgBXA7iv0Vz79u1LgjRY8IiCOHL2cOfAm9GjRydjckQSFt+i0sU52x9F4kpORhsHSUTVY7gv\nR8hZsWJFMmblypU9nhuIyzLzfYwyDFlEzQlGie7HqaeeWmlH2YSPP/54j/MCwOzZsyvtV155JRkz\nceLEpG/MmDFJH5OzrzwLpDnVlpqhp+zGHDV+HIDFZjYYtW8Cv3T3B8xsOYC7zezfADwH4M5er1QI\n0W80NHZ3/yOA5HcZ7r4WNf9dCHEAoAg6IQqh5Ykw7N+wvxcFmrDfGPl/OVsw5SRDMJH/l1OFNapu\nu3379ko78tFy/DYO9Nm5c2cyhv3xKDiIdY2omkt0HVFfozHRb2K4ms0nPvGJZMyCBQsq7Uh74HNF\nQVdcKWbChAkNzxWRq880YiC2ftabXYhCkLELUQgydiEKQcYuRCG0VKADGmeVRYEuHHgTiXFcrSQS\n8XgePiZ3PSwiRsEokSDG43IEukjY4oy61atXJ2NYRIwCRlgsjcTRqGw3V52JSjez+Blt2zRv3rxK\n+7bbbkvGMGeffXbSd/HFF1faO3bsSMbwdUyePDkZkyO0tcM+682iN7sQhSBjF6IQZOxCFELLt2zm\nAAj2PyO/kf2/yB+OkjEY9reioBr26yOfPae6TrT9cM62vbxFcFRx9eGHH660o2CUK664otKOAmZ4\nPVFwzoMPPpj08ZrOP//8ZAz76FFCzXXXXZf0May9RDpHR0dHj+2InG2tgAPbR2f0ZheiEGTsQhSC\njF2IQpCxC1EILRfouBINbyUUlfhlUS8KqmGxLafkbzQPB75EFU14TBSgEWXGsbDHbSAV6O65555k\nzA033FBp33rrrcmYHFiQijLBImGP13j66acnY1hYywmWigSynGxGPi5HaPtrEt5y0ZtdiEKQsQtR\nCDJ2IQqhpT77nj17Eh+dkygi/5d99qhSCie1RD4z+5FRIA776FHgzbRp0yrtSGdYs2ZN0sfbK0X+\n8L333ltpX3XVVckY9tGjRBwm8lG5L9pGavz48Q37ouM4+OXwww9PxrBv3awfLX88D73ZhSgEGbsQ\nhSBjF6IQZOxCFEJLBbr3338f69evr/Tx3t45e51HGVQsEkUZXLy90Ouvv56M4UCPk09uvIfl0qVL\nkz4WIoE0+ISz14BUtPvhD3vc8h5AfM+aEama2Q98f+fPmUdCWmvRm12IQpCxC1EIMnYhCkHGLkQh\ntFSg27t3b8M9tzijCkgzpqLsLI6qi6LKuORytNc37wceReKtWrWq0u7s7EzGnHTSSUkfl26Ost5u\nvvnmhmvkSMCczLBm6SsRTWLcwKM3uxCFIGMXohBk7EIUQkt9dndP/E1uR/4vlwaOfFSugBNVmOHy\nxtFWQhzAE+31zQEzU6ZMScZEmXA81/z585MxH//4x5M+JieIRQhGnxohCkHGLkQhZBu7mQ02s+fM\n7IF6+zgze8rM1pjZL8zskP5bphCit3yYN/v1AFZ0a38LwO3uPhXADgDX9OXChBB9S5ZAZ2YdAD4J\n4BYAX7ZahMRcAFfWhywG8HUAPaZoDRo0KAks2bhxY6UdlS9isSsqJ8VZblwCCgDOO++8SnvLli3J\nGA7qifb6ZsEwWnPOvu7R/vDRXIwCVEQz5L7ZvwvgRgBdeaRHA9jp7l1S+gYAx/bx2oQQfUhDYzez\nTwHodPdnmzmBmV1rZkvMbAn/mk0I0TpyvsafC+AyM7sUwBAARwH4HoDhZnZQ/e3eAWBjdLC73wHg\nDgAYOnRo40oIQoh+oaGxu/tXAXwVAMzsAgD/7O5XmdmvACwEcDeAqwHc12iuPXv2JEEzXHI4Cirh\nbwSRz8pBNKNHj07GcFJL5Ffv3r270h4xYkQyhvc1z9lTHgAOOaTxLyyi/ceF6At683v2r6Am1q1B\nzYe/s2+WJIToDz5UuKy7PwbgsfrPawGc1fdLEkL0B4qgE6IQZOxCFELL93rbtGlTpW/27NkNj2Mh\njTPTgDRbjivORPNwFlzXGrsTla1mQS5nrzUgFf/GjRuXjBk7dmzDeRRUI5pBb3YhCkHGLkQhyNiF\nKISW+uxA6m9y9dSouiz7zevWrUvG8PZCUQALB9VECTXs10fVZfm4FStWJGMiX3/hwoWV9mWXXdZw\njdo2SfQVerMLUQgydiEKQcYuRCHI2IUohJYKdIMHD072Y+cgm4kTJybHsUjFe7wDwJgxYyrtKOts\n+/btlTbv1w6k1WN4WykAWLlyZaUdiYHf/va3k76ZM2dW2jl7n0uME32F3uxCFIKMXYhCkLELUQgt\n9dknTpyIW265pdJ3zTXVCtRRdVXu40qyADBp0qRKe9++fckY3iIq8odztj/mirN8DUDqnwNpxR1V\npRGtRG92IQpBxi5EIcjYhSgEGbsQhdBSgW7kyJFYtGhRpY+z3G699dbkOA4+iSrM8BiuCgOkAlkU\nVMMCHWflAcD48eMr7Xnz5iVjIjjQRwEzopXozS5EIcjYhSgEGbsQhdBSn/3dd9/Fs89W94f84he/\nWGmfc845yXGrVq2qtHmbZwC46667Ku1oE0muHBsF8LAfH80zbdq0SnvGjBnJmIgoOUeIVqFPnxCF\nIGMXohBk7EIUgoxdiEKwnGopfXYyszcAvA5gFIC0ZnR7cyCuGTgw1601N88kdx8d/UNLjf0vJzVb\n4u6zWn7iXnAgrhk4MNetNfcP+hovRCHI2IUohIEy9jsG6Ly94UBcM3Bgrltr7gcGxGcXQrQefY0X\nohBabuxmNt/MVpnZGjO7qdXnz8HMfmxmnWb2Ure+kWb2kJmtrv89YiDXyJjZBDN71MyWm9kyM7u+\n3t+26zazIWb2tJm9UF/zN+r9x5nZU/XPyC/MLN2FY4Axs8Fm9pyZPVBvt/2aW2rsZjYYwA8AXALg\nFACLzOyUVq4hk58AmE99NwF4xN1PAPBIvd1OfADgBnc/BcA5AP6xfm/bed3vAZjr7mcAOBPAfDM7\nB8C3ANzu7lMB7ACQlu8deK4H0H2v7rZfc6vf7GcBWOPua939fQB3A1jQ4jU0xN0fB7CduhcAWFz/\neTGAy1u6qAa4+2Z3X1r/+W3UPojHoo3X7TW66nsfXP/jAOYC+HW9v63WDABm1gHgkwB+VG8b2nzN\nQOuN/VgA3Tdq21DvOxAY6+6b6z9vATB2IBfTE2Y2GcB0AE+hzddd/zr8PIBOAA8BeAXATnfvyi1u\nx8/IdwHcCKBrc4Kj0f5rlkDXDF77FUZb/hrDzI4AcA+AL7n7W93/rR3X7e573f1MAB2offM7eYCX\n1CNm9ikAne7+bMPBbUZLi1cA2AhgQrd2R73vQGCrmY1z981mNg61N1FbYWYHo2boP3P339S7237d\nAODuO83sUQBzAAw3s4Pqb8p2+4ycC+AyM7sUwBAARwH4Htp7zQBa/2Z/BsAJdeXyEABXALi/xWto\nlvsBXF3/+WoA9w3gWhLqfuOdAFa4+3e6/VPbrtvMRpvZ8PrPhwG4CDWt4VEAC+vD2mrN7v5Vd+9w\n98mofX7/192vQhuv+S+4e0v/ALgUwMuo+WY3t/r8mWv8OYDNAPag5n9dg5pf9giA1QAeBjByoNdJ\na/4Yal/R/wjg+fqfS9t53QBOB/Bcfc0vAfjXev8UAE8DWAPgVwAOHei17mf9FwB44EBZsyLohCgE\nCXRCFIKMXYhCkLELUQgydiEKQcYuRCHI2AvCzC43Mzezto5SE/2DjL0sFgF4ov53rzGzVkdgil4g\nYy+Eesz8x1ALELqi3neBmT1mZr82s5Vm9rN6JB7M7NJ637Nm9v1uedtfN7Ofmtn/AfipmT1uZmd2\nO88TZnZG669QNELGXg4LAPze3V8G8KaZzaz3TwfwJdTqC0wBcK6ZDQHwnwAucfeZALgO+SkA5rn7\nItRCdD8PAGZ2IoAh7v5Cf7moB9UAAAEsSURBVF+M+PDI2MthEWr1A1D/u+ur/NPuvsHd96EWYjsZ\ntcyzte7+an3Mz2mu+929a7vbXwH4VD0J5+9RK/wh2hD5XAVgZiNRK65wmpk5gMGoxdE/iFq1mC72\nIu8zsbvrB3d/18weQu2bw+cAzNzvUWJA0Zu9DBYC+Km7T3L3ye4+AcCrAM7bz/hVAKbUi2AAwN80\nmP9HAL4P4Bl339EH6xX9gIy9DBYBuJf67sF+VPn6V/TrAPzezJ4F8DaAXfub3GuFHN4CcFefrFb0\nC8p6EyFmdoS7v1NX538AYLW7376fseMBPAbg5LrvL9oQvdnF/viHem24ZQCGoabOJ5jZ36FW6+5m\nGXp7oze7EIWgN7sQhSBjF6IQZOxCFIKMXYhCkLELUQgydiEK4f8BXAjl5dVs9kQAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deaxf5X3mn68NYQn7YmP7Gmxj4wXC\nYoxpllGICwrDUhINmZQ2IyKhIE1SKVU7ash0NNNqWilRpSYMM+0IDVHpokKhjCBpmo7HA9O0CZjr\nYLAxYGyz2GCMzRaysfk7f/x+l7nneZ97f6/v8rvXPs9HQvg9fs8571len/t97vP9vpGZMMYc+syY\n6gEYY/qDJ7sxLcGT3ZiW4MluTEvwZDemJXiyG9MSxjXZI+LyiHgqIrZFxE0TNShjzMQTY/09e0TM\nBLAVwGUAdgF4GMB1mbllpH2OP/74nDVr1qjHff3114ttPMaf//znRZ+33nqr0Z4xo/x3jI+j+nzg\nAx9otN99992iD2+LiKKPYv/+/VX9DhR1He+9916jPZl+ippj19wjdRzebxzva8/xqGPXvDMzZ87s\neX5+9mqfY489ttE+8cQTiz697uOePXvwxhtvyE6H9RzlyKwGsC0zd3QHcQeAawCMONlnzZqFm2++\nubGNb8K3v/3tYj+eyJs3by76PPvss432EUccUfThSXr00UcXfQYGBhpt9Y/Pvn37Gm31ANTDVP9I\nMTxJ1XH4BVTX+uabbzba6h+tmhdZ7cf9VJ9e+yjGOtlr/hHlf8QPO6x89d9+++2ex+bjAMDxxx/f\n8/z87NU+a9asabQ/85nPFH0OP/zwRpvvx5e+9KURxzCeH+PnAdg5rL2ru80YMw2ZdIEuIm6MiMGI\nGHzjjTcm+3TGmBEYz2R/AcD8Ye2B7rYGmXlrZq7KzFU1P+4YYyaH8cTsDwNYEhEL0Znkvwrg10bb\nISKK2O1nP/tZo33ccccV+23YsKHR3rNnT9GnRlj76U9/2mir+O+ll15qtJcsWVL0mT9/fqP9i1/8\nouijxsjXXiM2cYwGlBqGiln5H1beR+33zjvv9ByP2k/Fv7xNHXssohlrGqqPgt8HpSEo7YOvVb1X\np556aqPN7xkA/OQnP2m01bXye7R9+/aiz7Jly4pttYx5smfmuxHxGwD+AcBMAN/KzMfHPBJjzKQy\nni87MvO7AL47QWMxxkwidtAZ0xLG9WWfCI455phG+8c//nHR55VXXmm0jzzyyKIPx/4qjj7hhBN6\njmfFihWN9tVXX1304bhR/X72+eefL7bt3bu30eYxA2X8qeJhvh/qnnH8qe5Hr+OOdGweY03MrK6j\nBr7XSsPg8yt9oCb2V3E8x9bK98BeDBWPs6b06quvFn12797daKtnxveRr2M0042/7Ma0BE92Y1qC\nJ7sxLcGT3ZiW0HeBjgUEttAq4YRNCjXJGUoQ4mSEuXPnFn2uvfbaRvvMM88s+vD5lWFl4cKFxTY2\nVqjrYAFKXQffj127do3pXCwAKSMQi4pAXUIPm1GU+MXblDmIxU/1fvA2JdC99tprjbYSHmuMPyef\nfHLR56STTmq0azI31XXw+ZcuXVr04XtUm3EJ+MtuTGvwZDemJXiyG9MS+hqzZ2YRc3D89+KLLxb7\ncXx11FFHFX04tlWxLhsbLr744qLP6aef3vM4bKz44Ac/WPRRsVRNUgWjrpWPvXjx4qIPx+wqOYNj\nS2WqUQYmfmYq/uR7pHQN3laTQMJFOYBS91GxPyerqPeMk6CAMtZWmZv8fqrYn/UJZQ7i90HF/lzN\nRt37kfCX3ZiW4MluTEvwZDemJXiyG9MS+irQRUQhLrGRgzN/gNLIUFPyV2WiMSzGDY1xOMoMwuKK\nEuNqTCQ1VVdqKr4qsYeNHirjb/bs2Y22Er+UqYbHxCIaUF6bEs1qxC8et3quLGRx9V+gLguQjTeq\nn3o/edynnXZa0efxx5t1XdTzYMFycHCw6HPGGWcU22rxl92YluDJbkxL8GQ3piVMuamG4y2uXAOU\ncVrNEjw1Szup1T04blLjqVnuR52fzRY1hoia46iKN4zSFdjEopJDVIzMFYDZsAKU97GmKo+Ko1mf\nUCanGnMSv2fKLKTMUWwgqnkevDqRQuksXL1m586dRR82EHHs70o1xhhPdmPagie7MS3Bk92YltBX\ngW7//v2FUMMCkBJOWBRRy/SwIKREGxYzVB8+jhKoWKBTJp+arDvVhwUWdX4eoxIMWQhVYiCfSwlU\naowsdqlssRrRkJ+1OleNgYlFNJUpyPdMLdetjs3mJGUO4utX4hsLvTWZgi+//HLRh69VreE+Ev6y\nG9MSPNmNaQme7Ma0hL6batg4wckXKo7mWE7FlpzEoAwzHDepc3FMpPrULFms4jaOyVTcxqYJFbfx\ncVTMzuNWhhU20dRqDxzvKuMRn0/dR9YjlD7B+6kx8r2uWXpavR8q/uX3Si3bxBqSeh7cR+kKfB9V\n5R6+fj6XTTXGGE92Y9qCJ7sxLcGT3ZiW0HdTDZsbWExRwgmLNMrYwMKaMk2waKSWMeI+NZViairO\nAOW1KRHvlFNOabRnzZpV9Kkx3vC1qXvG16qOo66Dj60qvNQIR1wWWQlbfC5V7pr71FQpUvdeiWbP\nPfdcz2Ox+KbuGR9bvecsVquKNzWGqpHwl92YluDJbkxL6DnZI+JbEfFyRGwetu2kiFgbEU93/19v\n0DXGTAk1MfufAfivAP582LabAKzLzK9FxE3d9ld6HSgiilhpYGCg0VamBUYZRBhVYZQTL1RCDce2\n6lysByh9QMXIbFBRfVgjUMsmsc6htAdORFHXwaaN2uV/OSbl2BsoKwKr6+D4W8X+nGRScx1q2SSu\ngKsSrhQc/6tYv+Z+cHUflSjE2+bMmVP04WQuvq9KLxii55c9M/8RAM/AawDc3v3z7QA+1es4xpip\nZawx++zMHCqg/RKA2aN1NsZMPeMW6LLzc8OIPztExI0RMRgRg2oRAmNMfxjrZN8TEXMAoPv/Mluj\nS2bempmrMnOVimWMMf1hrKaa+wBcD+Br3f/fW7PTzJkzi6VyWIR4+OGHi/1YdFACDAs3yujCIo0S\nM9ikoLK+WFhTP7GwIAOURgolEPK4azK4lLGCr02JeDyemiWrgLosRBboaow/6lqXL1/eczws7KlM\nQV5+SS1ZVVOSWsFjUstYsammxsB00UUXFX24bDe/9+MS6CLirwH8EMDSiNgVETegM8kvi4inAVza\nbRtjpjE9v+yZed0If/XLEzwWY8wkYgedMS2hr4kwM2bMKMwMNeYGjndU/MkxkIpdONZXlUBYRFTG\nl3vvbUoUygi0YMGCYtvcuXMbbY5rAW3QYTi2VQkcbJBRZhCOUZXxhaurqjGqCi9839S95rhZxcys\nh6jElB07djTaqtot32ulqYwW7w6h7hHff7UcM8fxaozch/UKQGsWtfjLbkxL8GQ3piV4shvTEjzZ\njWkJfRXoVNYbizLKoFIj5DDKVMPCnhKtuLzynXfeWfTZu3dvo83CGwBs2LCh2Hb33XfrwQ6DDTJc\nuQYoxb8zzzyz6LNixYpGW2W0sdCmDETKMMNiqBIon3/++UZbrVn+wgsvNNp79uwp+vAa5du3by/6\ncPltlVHGIuLHPvaxoo8SR/ldUwYm3qbuGb/X6j1fvHhxo63Ea773E5r1Zow5NPBkN6YleLIb0xI8\n2Y1pCX0V6IBSzODMK+VsYiFHOehq1gRjV5cSW374wx822lw2CwC+8IUvNNpKkFGi1bp16xrt733v\ne0UfLqelRCsWEVUGF49JiYgsACl3lnKM8fk5owwAHnzwwUZblYDevXt3o63ccTVrr/N1qKwzHrMS\nUE8//fRiG98TJZrxe6SEX36Oan28j3/84z3PxfeDjzOaw85fdmNagie7MS3Bk92YltD3mJ3NLmxk\nUGaDmtLRHDepqidsGlF9PvShDzXaH/nIR4o+bGxgkw2gY9Qzzjij0f70pz9d9OG4VZVXZj1CmYw4\nq0rFsTUahjIn8TNiAw0APP300422isc5E06ZenjcStPhjDau5qJQz0fpPKx9qHeR42Z1HXxvlYbC\n29QSUbXlvhX+shvTEjzZjWkJnuzGtARPdmNaQl8FuszsKQqpErtnnXVWo61KBTNK6OOSUyyYAWUG\nmToXZ14NDg4WfVSWFwtSSlhjQUiZerjskSqdxSW41Np3LHbViqPbtm1rtDdv3lz0UWWoGBa2lIGH\nBSklqvK2mtLeq1evLvqo57Fly5aefVggVAIdn79mDXdlzuH5cSCCnb/sxrQET3ZjWoInuzEtoe+m\nGo4v2ThQY4hQfdavX99oq9hq1qxZjfaiRYuKPrwfJ2sAZbKMWo5KxVtLlixptLnCClDqAcr8wcdR\npYs51lZmFI4RVRWYrVu3FtuefPLJUc+ltqnYkivKqHvG74s6l9IjesHvwkjnZ1ORSk7hY3HSDVBX\n3YiXQlP6hE01xpieeLIb0xI82Y1pCZ7sxrSEvgt0DItESkj6wQ9+0GjPmzev6MOGGWXOmT9/fqOt\n1ihjQUyJb72OCwCf+9znim28btott9xS9GGRSJlTnnnmmUa7JhNMiU9sKlICHYtxQCmIKVNPTYlj\nvm8q6+60005rtFVVnqeeeqrRrln7TpmllGjG91ZVJWJUKWsWFlUWIr+PKuNwPPjLbkxL8GQ3piV4\nshvTEvoes3PsxtUwV65cWezzyCOPNNqzZ88u+nAspaqn8PI6Krbj4ygDz7nnnttof+ITnyj6KMPO\nF7/4xUZ77dq1RZ9LL7200f7sZz9b9LnnnnsabWW0YF1DVU7lPmqpKWViYT1ExeyMWm6J77UyMHFl\n4euuu67ow8+Rk1cUqmov6wNAWUlJVTZmE43SJziOVzoLJ9CoxKDx4C+7MS3Bk92YluDJbkxL6DnZ\nI2J+RNwfEVsi4vGI+HJ3+0kRsTYinu7+v/yltTFm2lAj0L0L4Lcz80cRcSyADRGxFsDnAazLzK9F\nxE0AbgLwlV4HYzGJs8yWLVtW7HPRRRc12kpIYaOHEt9YoFMmDhZOLrjggqIPZ6up7CRVApoFKWUO\nuvLKKxttJZrxmNRxOINKiZqcwaVMRio7jIUkVfKY+1xxxRVFn+9///uNNi8ZBZQCqcpwO+eccxpt\nZbzhbcospUqCs4Cs3hkW+2qy1ThzESjvY41AN9pyT0XfXh0yc3dm/qj75zcBPAFgHoBrANze7XY7\ngE9Vn9UY03cOKGaPiAUALgDwEIDZmTn0u5KXAJSfjs4+N0bEYEQMqvxtY0x/qJ7sEXEMgL8F8JuZ\n2fjFYnZ+sVj+crHzd7dm5qrMXKX8wMaY/lBlqomIw9GZ6H+VmUOOjj0RMSczd0fEHAC9S76ijF24\nzSYGAFizZk2jrZJcOAZTphZO/FBVQI844ohR22qbquaya9euYttVV13VaK9atarowwYNdWyuyrpg\nwYKiD8e6aolgNsOoijcqtuRkIWUQ4X/YlRnlkksuabRV7M/6jKoUw8+ejUlAWV1IJZmopCPWTFTV\nYI7ZVbIM31ulhdSYk8azT40aHwBuA/BEZv7xsL+6D8D13T9fD+DeAxijMabP1HzZPwrg3wDYFBEb\nu9v+PYCvAfibiLgBwHMA/vXkDNEYMxH0nOyZ+U8ARqpy98sTOxxjzGRhB50xLaGvWW/79+8vhBoW\n6JS4wRVN1PI+bKJhUwlQCmvKIMHbVAYTH0eZWh577LFiG1dUUcYONkmoKjhsPFJ9uDKNyoxj84e6\nH0q0Y0FOCXQstqn12fn8XF0HKNeZVxVm+Nkr8Y2FPXVdCn6PlGDK74jKFOR3RGVTskCoDDNjEfHe\nP96Y9zTGHFR4shvTEjzZjWkJfY3ZZ8yYUcRXbPZX8TgbQpQTb/ny5Y22WjaJYykV27FhRxlvOJZS\nMStXswFKI4UycbAeoK6V40hl/OHED1Vdlq9D2ZnVGPkZKsMOb+PKugDw4osvNto7duwo+nDMrpJM\neNwqoYdjZKVhqG1sKtq0aVPRh99Z9c6wyUvpI5wUVvPu9TKpNfYd8W+MMYcUnuzGtARPdmNagie7\nMS1hypd/YhONMrGwaKYEKS5B/cADDxR91LrZDAuGytjAY1RCn6qUw8sLqf342Er8YrFNrUXP25Rw\nw+diwQzQoh0fW91XFpeUiMlmIFWBiKvHvPrqq0UffkbKeMJ9VDWbGkOXEkxrzr969epGWxmI+N1T\nAh0fm5+hmj/vj3PEvzHGHFJ4shvTEjzZjWkJnuzGtIS+CnQRUYgOLCgo4YT7qGwxFjxU1luNQMfj\nU44+duIpQUaVT2JhUe1X4/JjgUy5sVjsUeNhEVG57FSpKD62emacVabGyG44JQayG04JffxcVQks\nvmdKQOWyZUD5Ximhk8ek1iu88MILG20l/PI9UsKruo+9xvf+OUfd0xhzyODJbkxL8GQ3piX0NWbP\nzCIOYSOHilM4vlHGAe5z7LHHyvMPh9fMBsp13VXWF59LjVkZItQa6czOnTt7HptjfRVrcx8Vo/KS\nUKrCCq+PrvqpJZn4/GopIzaxqDHy9asS3Wy0UdoMx/GqUoyK2fkdUXoRG214OSqgfB+VFsRVeFSG\nH1e86RXDD8dfdmNagie7MS3Bk92YluDJbkxL6KtA99577xXiCYsQSjhhg4YSN1iAUVlFbFBRGVQs\nkqjjsNFDrT2n1vrevXt3oz0wMFD04cwvdWw+jjLncIadyuhiA4Yyxyjxj4VOtYY8i21qvXq+NpX1\n9swzzzTaSiDjMapMQRb61HiUQMllsdSxec2+s88+u+jD77kSLPn+q3ePTU58D531ZozxZDemLXiy\nG9MS+l6phuNLNgXUmGFUH47jlUGDjS41pZPZeKKoKfmrjq2SXHqVCgbK2FKtac/xnurDOocyaKil\npVgzUEs7sUFFxcP8zNRz5WekjsN6hHqu3EcZVlQCDR9L3SOO2VVcz+dTulPNXGDtYULXZzfGHBp4\nshvTEjzZjWkJnuzGtIQpLyVdUwqXhSwliDEq84mrtSjRis0OynhTUwVmNHPDEEqgYxFPZeaxuKPW\nGmdhT42HRSNVoluVTmYjBxtfgNL8UpMZqEQzNr8oUw0fWz0zNt6oCjzqXvN7dM011xR9eB07ZYTi\n8yuBrqZykLpHtfjLbkxL8GQ3piX0nOwRcWRErI+IRyPi8Yj4/e72hRHxUERsi4g7I6L8ucgYM22o\nidnfArAmM38SEYcD+KeI+HsAvwXgG5l5R0T8dwA3APjTyRgkx5vKSMBGBlWFlBMNVDICx1vKxNHL\nGAToeJy3KcMMx581JhJl4uBjK8MIb6updgsA5513XqPN1XVG2o/h8ykzDG9TyTo1yy/xNmV6Uskx\ny5Yta7SXL19e9GGTkTo2j1u9H6yPjFYpdiz0/LJnh6GRHt79LwGsAXB3d/vtAD41oSMzxkwoVTF7\nRMyMiI0AXgawFsB2AK9n5tBnaBeAeSPtb4yZeqome2a+l5nnAxgAsBrAsh67vE9E3BgRgxExWLNI\ngzFmcjggNT4zXwdwP4APAzghIoZi/gEAZRnSzj63ZuaqzFyl4mhjTH/oKdBFxKkA3snM1yPiKACX\nAfg6OpP+WgB3ALgewL01J+xloqkpE60MGixSKaMJV6FRfRglCHEVGGXyUcfmfkpIYtPErFmzij58\nrdu2bSv6MEowe+WVVxrtDRs2FH3UP9BcqUdV3OExqpLcNZlgbHRRphJ+P5Sphe+9qgKjzFFcFlod\nm99ZJb7xT7XK1MMmL3Wu8VCjxs8BcHtEzETnJ4G/yczvRMQWAHdExB8AeATAbRM6MmPMhNJzsmfm\nYwAuENt3oBO/G2MOAuygM6Yl9D0Rho0CNcYBjqVU3MZxk4rJOP5Ux2FjAy9PBZRjXrx4cdFHVXNl\n1Pm5Oomq3Mraw+bNm4s+GzdubLRV5VZe2klVxN2zZ0+x7aGHHmq0VWx59dVXN9oqjuWkFtWH77WK\nddnUpO4rx/7KCKW2cayvkmVqDEysmYw1eYnH6Eo1xpgCT3ZjWoInuzEtwZPdmJYw7SrVKMGOs9M4\nywgojRVKyOGKIkqQ4uWnVGYcb1NrmKu1vlkgVAIMi5HKsMPmi8svv7zow9liDz74YNGHx/3ss88W\nfdh4o86vKqow6lq5Mo4SyFgwVeYgPn9NhReV4bZo0aKex1bwu1djC1eZijVZkTXZeyPhL7sxLcGT\n3ZiW4MluTEvoe8zOMUZNFdYa4w3HcsrowUYGZX7g2G7evDJNn/dTJo59+/YV2zge54QSoLxWtYyV\nOjazYMGCRvvRRx8t+rBBpDYFmcetqvRyspIyzHAfpU+wyUiZWlifqYmHlaajko54TDXvooqjeT91\nP2oMMzVVeUYcV3VPY8xBjSe7MS3Bk92YluDJbkxLmHJTTY0pgEWS008/vejz0ksvNdqqwgwLN6ri\nza5du0bdByiFPmUGUWIXGzlU5hOLfWq5IzYDKaGRhUUlhM6ZM2fUNqCNNvzMlPGEBdOaSjVKoGNh\nS/Xh+6+WsWJDlRLjVFUePp8S1lgkU0tm8TNT78fs2bMbbfV+MjbVGGMKPNmNaQme7Ma0hCmP2RkV\nW3LiiTJE1FT54NhSxV9cmWbhwoVFH45HVYymzDAcgymDCBtmlImDx62q4vCxL7744qLPypUrG21V\n3XXTpk3FNk6OUUs283VwdR2gjIfnz5/fs4/SR/i51iQYqZhZmaP4/qsYmc+n3k9+H5SmxLpCTTx+\nIJWf/GU3piV4shvTEjzZjWkJnuzGtIRpJ9ApasS3mjXca4QU3lYj2qhqNmqMnIn36quvFn24Cg9n\nrwGluPP8888XfdjEoiq8sPi1fv36oo+qwsNZbyp7j8+vTDUsmtWs6a4y7Pg4SqTiPkpUVe8Di6rq\n2DXVlticpcxSLJCyYAfo97EWf9mNaQme7Ma0BE92Y1qCJ7sxLeGgFOhq+tSUBqrpo4Q+FtqUW06J\nTbyfEq1Y7FMlj3kddSX2sGNty5YtRR++/p07dxZ9VJYZC1LqWnkNeyUssRtOPeearLcDyfwaQmW4\nKXfegZR9GkKJsyzQKTGQhVclfI7lWt/fd8x7GmMOKjzZjWkJnuzGtIS+xuwR0bOUtCoBrarFMDXm\nB46/auK/GlONiuuU0YZRWXdPPvlko7127dqiD1ePURllHJMqc8zAwECjrTKx1BiXLFlSbGNYR6g5\ntrqPNcYbfvaqAhAfRxlWaqjRFWpKQKt3mpfsUu8Q60Pq+YyEv+zGtARPdmNaQvVkj4iZEfFIRHyn\n214YEQ9FxLaIuDMiyt8lGGOmDQfyZf8ygCeGtb8O4BuZuRjAawBumMiBGWMmliqBLiIGAFwJ4A8B\n/FZ0FIk1AH6t2+V2AL8H4E9HO86MGTOKrCUWJfbs2VPsx32UKMHllJVIw6aJM888s+jDAhmXqFbn\nUqWUa0oTqTJQp512WqOtyjuzsKhEKx6jEo1q+ihTD68bx+uxqWMpMwiX01KmFhaylNDH4qN6Hlxe\nWglkNWWqa9YmVH34fqh7xvea33ugHPdkCHTfBPA7AIZGfDKA1zNzSAbdBaBcAdEYM23oOdkj4ioA\nL2fmhl59R9j/xogYjIhB9S+VMaY/1PwY/1EAvxIRVwA4EsBxAG4GcEJEHNb9ug8AKH+RCyAzbwVw\nKwCcddZZvX8GMsZMCj0ne2Z+FcBXASAiLgHw7zLz1yPiLgDXArgDwPUA7u11rIgoYieOSVWJX453\nVEx06qmnNtqqEgnHciqurzGaMMoIpM7P51NLK/F1KAPLBRdc0GirhJpt27Y12nfddVfRhyvlLF++\nvOij4l8uU82lpYEy1lXLLTG89BYAXHjhhY22KpvN1X1UHMtaCN9nQCfHsLFF6Qqsz9Qk1KjkKT6/\nMtXUjGckxvN79q+gI9ZtQyeGv20cxzLGTDIHZJfNzAcAPND98w4Aqyd+SMaYycAOOmNagie7MS2h\nr1lvmVlkkbEApIScmgoznPmkhLVzzz23Zx8WSXjNbKAUCGvL+7KQpEpJ87GViMfizllnnVX04RLU\ny5YtK/qwGKoEKmUq2rhxY6OtnseOHTsabbWGPAtpSjBVgi1z8sknN9qLFi0q+px//vmNtsp6U4IY\nj1GZYdgopkTNmgw/fteUED0Wk88Q/rIb0xI82Y1pCZ7sxrSEKa8uy7E2t4EyTlExMseEyozCsZ1a\nV5z1ATYBAcBzzz3XaCuDhFp7nWNCZR/m61fXygkbvKY8UN4ztWwSx5aquixXsgXKOF6ZWNjUo5JM\neD9+PkAZsyvjDR9baQhs/KlJ3lHHUu/nWDWcXkxUtdsh/GU3piV4shvTEjzZjWkJnuzGtIS+C3Qs\nZrC4okwCLL7VZDUtXry46MMC2fbt24s+NSYfNsfUlDcG6owVe/fubbTV0k68n6omw1VwVGYej6f2\nOliA4vsBlMKWEui4vLMSLGvWVT/llFMabTVmvh9KxFPvXs3a65OFGs94zu8vuzEtwZPdmJbgyW5M\nS+j78k9sFGDziUpG4EogqlrJ0qVLR90HKGO5rVu3Fn0WLlzYaKuECY7juSItUGd+UNfBsaRKluH4\nUxlN2PiiYnaO/1Q8qOJffmbqXrNpRcXsfD6lxfC4VbIO76eSbjj2rzWn8Bhr4uixLqvMY6qJzw/k\nXP6yG9MSPNmNaQme7Ma0BE92Y1pCXwW6/fv3F+IJZ5XNnTu32I+NFEo0U1lMDIsrSshh8UlltLFA\np0wtTz31VLGNhSxV0YSvtSY7S1Vm4TENDg4WfdgMU2MEAspnxuIXUApHSkiqOQ7fD1W5Z9++fY22\nqtzDpaNrsteAsYlmE0XNWvAHgr/sxrQET3ZjWoInuzEtoa8x+9FHH10s58NJDCqOZZQhombpWt5P\nGTQ48URVHeE4Xi39rCrXchyvKrOw6UgZb9igcuKJJxZ9WHtQ18HagzLw1CzHpY5dE+tyzK6SXLgq\n0JYtW4o+/M588pOfLPrw+dWSWepe9zMRhnWNiT6Xv+zGtARPdmNagie7MS3Bk92YlhAHsnzMuE8W\nsRfAcwBOAbCvR/fpxsE4ZuDgHLfHPHbOyMxy8Xn0ebK/f9KIwcxc1fcTj4ODcczAwTluj3ly8I/x\nxrQET3ZjWsJUTfZbp+i8406EousAAAUwSURBVOFgHDNwcI7bY54EpiRmN8b0H/8Yb0xL6Ptkj4jL\nI+KpiNgWETf1+/w1RMS3IuLliNg8bNtJEbE2Ip7u/r80pE8hETE/Iu6PiC0R8XhEfLm7fdqOOyKO\njIj1EfFod8y/392+MCIe6r4jd0ZEWdFyiomImRHxSER8p9ue9mPu62SPiJkA/huAfwlgBYDrImJF\nP8dQyZ8BuJy23QRgXWYuAbCu255OvAvgtzNzBYBfAvCl7r2dzuN+C8CazDwPwPkALo+IXwLwdQDf\nyMzFAF4DcMMUjnEkvgzgiWHtaT/mfn/ZVwPYlpk7MvNtAHcAuKbPY+hJZv4jAE4BuwbA7d0/3w7g\nU30dVA8yc3dm/qj75zfReRHnYRqPOzsMpQce3v0vAawBcHd3+7QaMwBExACAKwH8j247MM3HDPR/\nss8DsHNYe1d328HA7MwcquP0EoDZUzmY0YiIBQAuAPAQpvm4uz8ObwTwMoC1ALYDeD0zh+pGTcd3\n5JsAfgfAUB7vyZj+Y7ZANxay8yuMaflrjIg4BsDfAvjNzGwko0/HcWfme5l5PoABdH7yWzbFQxqV\niLgKwMuZuWGqx3Kg9HsV1xcAzB/WHuhuOxjYExFzMnN3RMxB50s0rYiIw9GZ6H+Vmfd0N0/7cQNA\nZr4eEfcD+DCAEyLisO6Xcrq9Ix8F8CsRcQWAIwEcB+BmTO8xA+j/l/1hAEu6yuUHAPwqgPv6PIax\nch+A67t/vh7AvVM4loJu3HgbgCcy84+H/dW0HXdEnBoRJ3T/fBSAy9DRGu4HcG2327Qac2Z+NTMH\nMnMBOu/v/8nMX8c0HvP7ZGZf/wNwBYCt6MRmv9vv81eO8a8B7AbwDjrx1w3oxGXrADwN4H8DOGmq\nx0lj/hg6P6I/BmBj978rpvO4AZwL4JHumDcD+I/d7YsArAewDcBdAI6Y6rGOMP5LAHznYBmzHXTG\ntAQLdMa0BE92Y1qCJ7sxLcGT3ZiW4MluTEvwZD/EiIjf7WaQPRYRGyPi4kk6z3eHfkduDg767aAz\nk0hEfBjAVQBWZuZbEXEKgKpUy2Hur179Ap2iJ1eMb7Sm3/jLfmgxB8C+zHwLADJzX2a+GBHPdic+\nImJVRDzQ/fPvRcRfRMQ/A/iLiPh8RNwbEQ9089//U7ffgm4Ngj9Hx/wyf+iYEfHBiPi7bk765oj4\nbHefCyPi/0bEhoj4h65V10whnuyHFv8LnYm4NSL+JCI+XrHPCgCXZuZ13fZqAP8KHXfbZyJiqDzy\nEgB/kplnZ+bw1RYvB/BiZp6XmecA+F7Xo38LgGsz80IA3wLwh+O/PDMePNkPIbKTG34hgBsB7AVw\nZ0R8vsdu92Xmz4e112bmK91t96BjwwWA5zLzQbH/JgCXRcTXI+JfZOYbAJYCOAfA2m766n9AJznE\nTCGO2Q8xMvM9AA8AeCAiNqGTlPEu/v8/7EfSLrx2Mfunc4R+Q+fbGhEr0fHh/0FErAPwPwE8npkf\nHtNFmEnBX/ZDiIhYGhFLhm06H53ltp5F54sPdH5EH43LunXrjkKn2so/9zjnXAA/y8y/BPBHAFYC\neArAqV3BEBFxeEScfaDXYyYWf9kPLY4BcEv3V2LvopOBdSOA5QBui4j/jM5XfzTWo5MTPwDgLzNz\nsFv5ZiQ+BOCPImI/OlmC/zYz346IawH8l4g4Hp337JsAHh/rhZnx46w38z7d+H5VZv7GVI/FTDz+\nMd6YluAvuzEtwV92Y1qCJ7sxLcGT3ZiW4MluTEvwZDemJXiyG9MS/h+XvCTjLS5CGgAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycW0ruOU7dD8",
        "colab_type": "text"
      },
      "source": [
        "For modeling purposes, we are going to use the following three architectures:\n",
        "- Shallow fully connected network\n",
        "- Mini InceptionNet or Mini GoogLeNet\n",
        "- Mini VGGNet\n",
        "\n",
        "For architectural details and discussions follow this article: https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I5CZdTdJEgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comes from http://bit.ly/2U8ntCX\n",
        "!wget https://raw.githubusercontent.com/sayakpaul/ML-Bootcamp-Launchpad/master/pyimagesearch/models.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_-6F86LRdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyImageSearch imports\n",
        "from models import MiniVGGNetModel\n",
        "from models import minigooglenet_functional\n",
        "from models import shallownet_sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0acbio2XL9za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convnets would require a channel dimension\n",
        "trainX = trainX.reshape(-1, 48, 48, 1)\n",
        "valX = valX.reshape(-1, 48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUb9Vu1gNvQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up wandb\n",
        "!pip install wandb\n",
        "!wandb login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV-4dpBHOCsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNR-beYTQm7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import EarlyStopping callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTW1wT5ION74",
        "colab_type": "code",
        "outputId": "7d12c279-4e0e-4be5-8b32-94697e533431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Train our first shallow model\n",
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"shallow-convnet\")\n",
        "shallow_model = shallownet_sequential(48, 48, 1, len(LABELS))\n",
        "shallow_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "shallow_model.fit(trainX, trainY,  validation_data=(valX, valY), epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", labels=LABELS),\n",
        "               EarlyStopping(patience=5, restore_best_weights=True)])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/shallow-convnet\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/shallow-convnet</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24402 samples, validate on 4307 samples\n",
            "Epoch 1/50\n",
            "24402/24402 [==============================] - 12s 473us/sample - loss: 1.6707 - accuracy: 0.3496 - val_loss: 1.5725 - val_accuracy: 0.4086\n",
            "Epoch 2/50\n",
            "24402/24402 [==============================] - 4s 161us/sample - loss: 1.4411 - accuracy: 0.4560 - val_loss: 1.5159 - val_accuracy: 0.4191\n",
            "Epoch 3/50\n",
            "24402/24402 [==============================] - 4s 166us/sample - loss: 1.3046 - accuracy: 0.5113 - val_loss: 1.5106 - val_accuracy: 0.4305\n",
            "Epoch 4/50\n",
            "24402/24402 [==============================] - 4s 160us/sample - loss: 1.1790 - accuracy: 0.5676 - val_loss: 1.5131 - val_accuracy: 0.4418\n",
            "Epoch 5/50\n",
            "24402/24402 [==============================] - 4s 166us/sample - loss: 1.0693 - accuracy: 0.6138 - val_loss: 1.5360 - val_accuracy: 0.4514\n",
            "Epoch 6/50\n",
            "24402/24402 [==============================] - 4s 162us/sample - loss: 0.9691 - accuracy: 0.6528 - val_loss: 1.5535 - val_accuracy: 0.4518\n",
            "Epoch 7/50\n",
            "24402/24402 [==============================] - 4s 163us/sample - loss: 0.8797 - accuracy: 0.6897 - val_loss: 1.6330 - val_accuracy: 0.4418\n",
            "Epoch 8/50\n",
            "24402/24402 [==============================] - 4s 165us/sample - loss: 0.7924 - accuracy: 0.7253 - val_loss: 1.6849 - val_accuracy: 0.4479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3003243c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf8xrKWb74sO",
        "colab_type": "text"
      },
      "source": [
        "The model terribly overfits. Let's try out the other variants. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL6i8OS3PFwr",
        "colab_type": "code",
        "outputId": "5f5e6143-25dc-4606-e7f2-6913f4c0f31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Train a mini inception net\n",
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"miniinception-net\")\n",
        "inception_net = minigooglenet_functional(48, 48, 1, len(LABELS))\n",
        "inception_net.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "inception_net.fit(trainX, trainY,  validation_data=(valX, valY), epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", labels=LABELS),\n",
        "               EarlyStopping(patience=5, restore_best_weights=True)])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/miniinception-net\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/miniinception-net</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24402 samples, validate on 4307 samples\n",
            "Epoch 1/50\n",
            "24402/24402 [==============================] - 44s 2ms/sample - loss: 1.6965 - accuracy: 0.3152 - val_loss: 1.5769 - val_accuracy: 0.3875\n",
            "Epoch 2/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 1.3275 - accuracy: 0.4958 - val_loss: 1.3844 - val_accuracy: 0.4662\n",
            "Epoch 3/50\n",
            "24402/24402 [==============================] - 40s 2ms/sample - loss: 1.1703 - accuracy: 0.5587 - val_loss: 1.2896 - val_accuracy: 0.4999\n",
            "Epoch 4/50\n",
            "24402/24402 [==============================] - 41s 2ms/sample - loss: 1.0896 - accuracy: 0.5936 - val_loss: 1.2456 - val_accuracy: 0.5342\n",
            "Epoch 5/50\n",
            "24402/24402 [==============================] - 40s 2ms/sample - loss: 1.0178 - accuracy: 0.6194 - val_loss: 1.1717 - val_accuracy: 0.5603\n",
            "Epoch 6/50\n",
            "24402/24402 [==============================] - 40s 2ms/sample - loss: 0.9557 - accuracy: 0.6415 - val_loss: 1.1800 - val_accuracy: 0.5828\n",
            "Epoch 7/50\n",
            "24402/24402 [==============================] - 41s 2ms/sample - loss: 0.8832 - accuracy: 0.6724 - val_loss: 1.1609 - val_accuracy: 0.5888\n",
            "Epoch 8/50\n",
            "24402/24402 [==============================] - 41s 2ms/sample - loss: 0.8021 - accuracy: 0.7003 - val_loss: 1.1564 - val_accuracy: 0.5811\n",
            "Epoch 9/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 0.7159 - accuracy: 0.7353 - val_loss: 1.2120 - val_accuracy: 0.5809\n",
            "Epoch 10/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 0.6127 - accuracy: 0.7717 - val_loss: 1.4091 - val_accuracy: 0.5765\n",
            "Epoch 11/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 0.5014 - accuracy: 0.8158 - val_loss: 1.5350 - val_accuracy: 0.5498\n",
            "Epoch 12/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 0.3952 - accuracy: 0.8548 - val_loss: 1.7404 - val_accuracy: 0.5633\n",
            "Epoch 13/50\n",
            "24402/24402 [==============================] - 39s 2ms/sample - loss: 0.3208 - accuracy: 0.8818 - val_loss: 1.7900 - val_accuracy: 0.5010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2e9622cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCHL0j3-SDYh",
        "colab_type": "code",
        "outputId": "57a962cc-8a4c-4d2e-d73f-552b627ec7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Train a mini VGG net\n",
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-net\")\n",
        "vgg_net = MiniVGGNetModel(len(LABELS))\n",
        "vgg_net.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "vgg_net.fit(trainX, trainY,  validation_data=(valX, valY), epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", labels=LABELS),\n",
        "               EarlyStopping(patience=5, restore_best_weights=True)])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24402 samples, validate on 4307 samples\n",
            "Epoch 1/50\n",
            "24224/24402 [============================>.] - ETA: 0s - loss: 1.8384 - accuracy: 0.3645"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24402/24402 [==============================] - 9s 357us/sample - loss: 1.8358 - accuracy: 0.3650 - val_loss: 1.4292 - val_accuracy: 0.4574\n",
            "Epoch 2/50\n",
            "24402/24402 [==============================] - 7s 293us/sample - loss: 1.3762 - accuracy: 0.4754 - val_loss: 1.4673 - val_accuracy: 0.4541\n",
            "Epoch 3/50\n",
            "24402/24402 [==============================] - 7s 295us/sample - loss: 1.2610 - accuracy: 0.5232 - val_loss: 1.3198 - val_accuracy: 0.5013\n",
            "Epoch 4/50\n",
            "24402/24402 [==============================] - 7s 300us/sample - loss: 1.1733 - accuracy: 0.5597 - val_loss: 1.2651 - val_accuracy: 0.5168\n",
            "Epoch 5/50\n",
            "24402/24402 [==============================] - 8s 311us/sample - loss: 1.1138 - accuracy: 0.5832 - val_loss: 1.2914 - val_accuracy: 0.5226\n",
            "Epoch 6/50\n",
            "24402/24402 [==============================] - 8s 319us/sample - loss: 1.0487 - accuracy: 0.6077 - val_loss: 1.2543 - val_accuracy: 0.5289\n",
            "Epoch 7/50\n",
            "24402/24402 [==============================] - 8s 308us/sample - loss: 0.9866 - accuracy: 0.6324 - val_loss: 1.3595 - val_accuracy: 0.5326\n",
            "Epoch 8/50\n",
            "24402/24402 [==============================] - 7s 294us/sample - loss: 0.9214 - accuracy: 0.6550 - val_loss: 1.3650 - val_accuracy: 0.5055\n",
            "Epoch 9/50\n",
            "24402/24402 [==============================] - 7s 292us/sample - loss: 0.8487 - accuracy: 0.6855 - val_loss: 1.3354 - val_accuracy: 0.5396\n",
            "Epoch 10/50\n",
            "24402/24402 [==============================] - 7s 300us/sample - loss: 0.7553 - accuracy: 0.7226 - val_loss: 1.4107 - val_accuracy: 0.5245\n",
            "Epoch 11/50\n",
            "24402/24402 [==============================] - 7s 305us/sample - loss: 0.6755 - accuracy: 0.7534 - val_loss: 1.4790 - val_accuracy: 0.5493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd315be76d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeJ-1Ac3X5uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a data augmentation pipeline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_aug = ImageDataGenerator(zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2)\n",
        "val_aug = ImageDataGenerator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YevbwwSYbdd",
        "colab_type": "code",
        "outputId": "0c4bf65a-2068-49ea-f3d7-6c9d6ff644fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train a mini VGG net with data augmentation & SGD\n",
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-net-da-sgd\")\n",
        "vgg_net = MiniVGGNetModel(len(LABELS))\n",
        "vgg_net.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "vgg_net.fit(train_aug.flow(trainX, trainY, batch_size=64),\n",
        "    steps_per_epoch=np.ceil(len(trainX)/64),\n",
        "    validation_data=val_aug.flow(valX, valY, batch_size=64), \n",
        "    validation_steps=np.ceil(len(valX)/64) ,\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS),\n",
        "               EarlyStopping(patience=5, restore_best_weights=True)])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net-da-sgd\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net-da-sgd</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-32-2892580624a1>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 382.0 steps, validate for 68.0 steps\n",
            "Epoch 1/50\n",
            "381/382 [============================>.] - ETA: 0s - loss: 2.4246 - accuracy: 0.1944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "382/382 [==============================] - 12s 31ms/step - loss: 2.4240 - accuracy: 0.1945 - val_loss: 1.8179 - val_accuracy: 0.2719\n",
            "Epoch 2/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.9648 - accuracy: 0.2374 - val_loss: 1.7142 - val_accuracy: 0.3169\n",
            "Epoch 3/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.8344 - accuracy: 0.2634 - val_loss: 1.7271 - val_accuracy: 0.3139\n",
            "Epoch 4/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.7871 - accuracy: 0.2818 - val_loss: 1.6877 - val_accuracy: 0.3320\n",
            "Epoch 5/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.7530 - accuracy: 0.2958 - val_loss: 1.6843 - val_accuracy: 0.3313\n",
            "Epoch 6/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.7362 - accuracy: 0.3001 - val_loss: 1.8613 - val_accuracy: 0.2433\n",
            "Epoch 7/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.7115 - accuracy: 0.3135 - val_loss: 1.6153 - val_accuracy: 0.3696\n",
            "Epoch 8/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.6883 - accuracy: 0.3288 - val_loss: 1.7212 - val_accuracy: 0.3234\n",
            "Epoch 9/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.6699 - accuracy: 0.3385 - val_loss: 1.5927 - val_accuracy: 0.3752\n",
            "Epoch 10/50\n",
            "382/382 [==============================] - 11s 27ms/step - loss: 1.6517 - accuracy: 0.3463 - val_loss: 1.6795 - val_accuracy: 0.3436\n",
            "Epoch 11/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.6377 - accuracy: 0.3519 - val_loss: 1.5765 - val_accuracy: 0.3829\n",
            "Epoch 12/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.6199 - accuracy: 0.3631 - val_loss: 1.6696 - val_accuracy: 0.3464\n",
            "Epoch 13/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.6039 - accuracy: 0.3714 - val_loss: 1.5280 - val_accuracy: 0.4077\n",
            "Epoch 14/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.5913 - accuracy: 0.3793 - val_loss: 1.5138 - val_accuracy: 0.4065\n",
            "Epoch 15/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.5771 - accuracy: 0.3824 - val_loss: 1.4977 - val_accuracy: 0.4226\n",
            "Epoch 16/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.5582 - accuracy: 0.3947 - val_loss: 1.5228 - val_accuracy: 0.4163\n",
            "Epoch 17/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.5468 - accuracy: 0.3974 - val_loss: 1.4815 - val_accuracy: 0.4409\n",
            "Epoch 18/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.5415 - accuracy: 0.4022 - val_loss: 1.5061 - val_accuracy: 0.4321\n",
            "Epoch 19/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.5259 - accuracy: 0.4119 - val_loss: 1.4449 - val_accuracy: 0.4451\n",
            "Epoch 20/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.5020 - accuracy: 0.4208 - val_loss: 1.3686 - val_accuracy: 0.4799\n",
            "Epoch 21/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.4920 - accuracy: 0.4219 - val_loss: 1.6666 - val_accuracy: 0.3845\n",
            "Epoch 22/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.4888 - accuracy: 0.4262 - val_loss: 1.3647 - val_accuracy: 0.4797\n",
            "Epoch 23/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.4730 - accuracy: 0.4308 - val_loss: 1.3968 - val_accuracy: 0.4611\n",
            "Epoch 24/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.4595 - accuracy: 0.4391 - val_loss: 1.3939 - val_accuracy: 0.4690\n",
            "Epoch 25/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.4499 - accuracy: 0.4430 - val_loss: 1.3534 - val_accuracy: 0.4857\n",
            "Epoch 26/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.4330 - accuracy: 0.4499 - val_loss: 1.3991 - val_accuracy: 0.4634\n",
            "Epoch 27/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.4255 - accuracy: 0.4528 - val_loss: 1.3411 - val_accuracy: 0.4795\n",
            "Epoch 28/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.4162 - accuracy: 0.4568 - val_loss: 1.3423 - val_accuracy: 0.4860\n",
            "Epoch 29/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.4104 - accuracy: 0.4558 - val_loss: 1.4644 - val_accuracy: 0.4451\n",
            "Epoch 30/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.3986 - accuracy: 0.4616 - val_loss: 1.3625 - val_accuracy: 0.4750\n",
            "Epoch 31/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.3896 - accuracy: 0.4650 - val_loss: 1.4042 - val_accuracy: 0.4602\n",
            "Epoch 32/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3835 - accuracy: 0.4690 - val_loss: 1.2962 - val_accuracy: 0.5080\n",
            "Epoch 33/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3805 - accuracy: 0.4702 - val_loss: 1.2974 - val_accuracy: 0.5113\n",
            "Epoch 34/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.3705 - accuracy: 0.4748 - val_loss: 1.2950 - val_accuracy: 0.5143\n",
            "Epoch 35/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.3601 - accuracy: 0.4810 - val_loss: 1.3093 - val_accuracy: 0.5043\n",
            "Epoch 36/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3541 - accuracy: 0.4804 - val_loss: 1.2576 - val_accuracy: 0.5205\n",
            "Epoch 37/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3541 - accuracy: 0.4802 - val_loss: 1.2411 - val_accuracy: 0.5287\n",
            "Epoch 38/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.3439 - accuracy: 0.4851 - val_loss: 1.2712 - val_accuracy: 0.5224\n",
            "Epoch 39/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3298 - accuracy: 0.4912 - val_loss: 1.2603 - val_accuracy: 0.5166\n",
            "Epoch 40/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3317 - accuracy: 0.4909 - val_loss: 1.3448 - val_accuracy: 0.4885\n",
            "Epoch 41/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3273 - accuracy: 0.4898 - val_loss: 1.2945 - val_accuracy: 0.5152\n",
            "Epoch 42/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.3227 - accuracy: 0.4928 - val_loss: 1.2356 - val_accuracy: 0.5387\n",
            "Epoch 43/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3182 - accuracy: 0.5002 - val_loss: 1.2284 - val_accuracy: 0.5391\n",
            "Epoch 44/50\n",
            "382/382 [==============================] - 12s 31ms/step - loss: 1.3119 - accuracy: 0.4982 - val_loss: 1.2236 - val_accuracy: 0.5361\n",
            "Epoch 45/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.3091 - accuracy: 0.4986 - val_loss: 1.2615 - val_accuracy: 0.5226\n",
            "Epoch 46/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 1.2983 - accuracy: 0.5039 - val_loss: 1.2487 - val_accuracy: 0.5277\n",
            "Epoch 47/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.2993 - accuracy: 0.4996 - val_loss: 1.2813 - val_accuracy: 0.5161\n",
            "Epoch 48/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.2956 - accuracy: 0.5029 - val_loss: 1.2040 - val_accuracy: 0.5445\n",
            "Epoch 49/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.2876 - accuracy: 0.5094 - val_loss: 1.2028 - val_accuracy: 0.5505\n",
            "Epoch 50/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 1.2866 - accuracy: 0.5129 - val_loss: 1.1831 - val_accuracy: 0.5572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd318f20ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Wjv-Lh7NyB",
        "colab_type": "text"
      },
      "source": [
        "Let's train the network with cylical learning rates. You can learn more about it from here: https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivyZ_A8bY1j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the CLR callback\n",
        "!wget https://raw.githubusercontent.com/sayakpaul/ML-Bootcamp-Launchpad/master/pyimagesearch/clr_callback.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_UiMRkbXV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from clr_callback import CyclicLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsq8SjHebmUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the step size and initialize the cyclic learning\n",
        "# rate method\n",
        "step_size = 8 * np.ceil(len(trainX)//64)\n",
        "clr = CyclicLR(\n",
        "\tmode=\"triangular\",\n",
        "\tbase_lr=1e-5,\n",
        "\tmax_lr=1e-3,\n",
        "\tstep_size=step_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bLPNYS7cObC",
        "colab_type": "code",
        "outputId": "9fe5b9ff-3316-416b-8909-6eb0b1f1d882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train a mini VGG net with data augmentation, SGD & CLR\n",
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-net-daug-sgd-clr\")\n",
        "vgg_net = MiniVGGNetModel(len(LABELS))\n",
        "vgg_net.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "vgg_net.fit(train_aug.flow(trainX, trainY, batch_size=64),\n",
        "    steps_per_epoch=np.ceil(len(trainX)/64),\n",
        "    validation_data=val_aug.flow(valX, valY, batch_size=64), \n",
        "    validation_steps=np.ceil(len(valX)/64) ,\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS),\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    clr])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net-daug-sgd-clr\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-net-daug-sgd-clr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 382.0 steps, validate for 68.0 steps\n",
            "Epoch 1/50\n",
            "381/382 [============================>.] - ETA: 0s - loss: 3.1788 - accuracy: 0.1455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "382/382 [==============================] - 12s 31ms/step - loss: 3.1783 - accuracy: 0.1457 - val_loss: 2.0538 - val_accuracy: 0.2097\n",
            "Epoch 2/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 3.0211 - accuracy: 0.1590 - val_loss: 2.4739 - val_accuracy: 0.2034\n",
            "Epoch 3/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.8765 - accuracy: 0.1718 - val_loss: 2.3809 - val_accuracy: 0.2141\n",
            "Epoch 4/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.7644 - accuracy: 0.1762 - val_loss: 2.3144 - val_accuracy: 0.2113\n",
            "Epoch 5/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.6537 - accuracy: 0.1874 - val_loss: 2.0491 - val_accuracy: 0.2703\n",
            "Epoch 6/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 2.5536 - accuracy: 0.1897 - val_loss: 2.0896 - val_accuracy: 0.2266\n",
            "Epoch 7/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.4507 - accuracy: 0.1992 - val_loss: 1.9503 - val_accuracy: 0.2986\n",
            "Epoch 8/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 2.3656 - accuracy: 0.2081 - val_loss: 2.1026 - val_accuracy: 0.2779\n",
            "Epoch 9/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.2921 - accuracy: 0.2144 - val_loss: 1.8722 - val_accuracy: 0.2967\n",
            "Epoch 10/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 2.2169 - accuracy: 0.2242 - val_loss: 1.9339 - val_accuracy: 0.2986\n",
            "Epoch 11/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 2.1774 - accuracy: 0.2288 - val_loss: 1.7625 - val_accuracy: 0.3244\n",
            "Epoch 12/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.1497 - accuracy: 0.2261 - val_loss: 1.7590 - val_accuracy: 0.3297\n",
            "Epoch 13/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.1153 - accuracy: 0.2377 - val_loss: 1.7525 - val_accuracy: 0.3364\n",
            "Epoch 14/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 2.0841 - accuracy: 0.2477 - val_loss: 1.7242 - val_accuracy: 0.3429\n",
            "Epoch 15/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 2.0784 - accuracy: 0.2428 - val_loss: 1.7184 - val_accuracy: 0.3446\n",
            "Epoch 16/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.0702 - accuracy: 0.2485 - val_loss: 1.7143 - val_accuracy: 0.3401\n",
            "Epoch 17/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.0630 - accuracy: 0.2500 - val_loss: 1.7245 - val_accuracy: 0.3381\n",
            "Epoch 18/50\n",
            "382/382 [==============================] - 11s 30ms/step - loss: 2.0570 - accuracy: 0.2491 - val_loss: 1.7085 - val_accuracy: 0.3418\n",
            "Epoch 19/50\n",
            "382/382 [==============================] - 11s 29ms/step - loss: 2.0578 - accuracy: 0.2486 - val_loss: 1.7119 - val_accuracy: 0.3466\n",
            "Epoch 20/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.0407 - accuracy: 0.2537 - val_loss: 1.7814 - val_accuracy: 0.3278\n",
            "Epoch 21/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 2.0182 - accuracy: 0.2583 - val_loss: 1.7173 - val_accuracy: 0.3383\n",
            "Epoch 22/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.9932 - accuracy: 0.2608 - val_loss: 1.6871 - val_accuracy: 0.3478\n",
            "Epoch 23/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.9781 - accuracy: 0.2614 - val_loss: 1.6565 - val_accuracy: 0.3576\n",
            "Epoch 24/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.9489 - accuracy: 0.2699 - val_loss: 1.8021 - val_accuracy: 0.3190\n",
            "Epoch 25/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.9150 - accuracy: 0.2767 - val_loss: 1.7406 - val_accuracy: 0.3267\n",
            "Epoch 26/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8893 - accuracy: 0.2835 - val_loss: 1.6385 - val_accuracy: 0.3715\n",
            "Epoch 27/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.8760 - accuracy: 0.2851 - val_loss: 1.6723 - val_accuracy: 0.3434\n",
            "Epoch 28/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8587 - accuracy: 0.2938 - val_loss: 1.6747 - val_accuracy: 0.3508\n",
            "Epoch 29/50\n",
            "382/382 [==============================] - 11s 28ms/step - loss: 1.8378 - accuracy: 0.2964 - val_loss: 1.6279 - val_accuracy: 0.3648\n",
            "Epoch 30/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8242 - accuracy: 0.3019 - val_loss: 1.6151 - val_accuracy: 0.3738\n",
            "Epoch 31/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8297 - accuracy: 0.2967 - val_loss: 1.6133 - val_accuracy: 0.3680\n",
            "Epoch 32/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8216 - accuracy: 0.3033 - val_loss: 1.6109 - val_accuracy: 0.3696\n",
            "Epoch 33/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8169 - accuracy: 0.3057 - val_loss: 1.6096 - val_accuracy: 0.3724\n",
            "Epoch 34/50\n",
            "382/382 [==============================] - 10s 26ms/step - loss: 1.8236 - accuracy: 0.3010 - val_loss: 1.6238 - val_accuracy: 0.3659\n",
            "Epoch 35/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8174 - accuracy: 0.3018 - val_loss: 1.6503 - val_accuracy: 0.3562\n",
            "Epoch 36/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8176 - accuracy: 0.3004 - val_loss: 1.6495 - val_accuracy: 0.3529\n",
            "Epoch 37/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.8067 - accuracy: 0.3013 - val_loss: 1.7212 - val_accuracy: 0.3320\n",
            "Epoch 38/50\n",
            "382/382 [==============================] - 10s 27ms/step - loss: 1.7904 - accuracy: 0.3129 - val_loss: 1.6545 - val_accuracy: 0.3566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3181dc278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl-YB3dg_O8v",
        "colab_type": "text"
      },
      "source": [
        "Jeremy Howard discussed a very nice idea of progressively increasing the number of channels in the initial layers of a Convnet while keeping the kernel size to 3x3. This is discussed here: https://youtu.be/hPQKzsjTyyQ?t=3700. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNA_MgR8otlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z45jjxiI_gVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MiniVGGNetModel(Model):\n",
        "\tdef __init__(self, classes, channels, init_kernel_size=3, chanDim=-1):\n",
        "\t\t# call the parent constructor\n",
        "\t\tsuper(MiniVGGNetModel, self).__init__()\n",
        "\n",
        "\t\t# determine the number of channels to output in the first\n",
        "\t\t# conv layer\n",
        "\t\toutChannels = 2**math.floor(math.log2(channels*init_kernel_size*init_kernel_size))\n",
        "\n",
        "\t\t# initialize the layers in the first (CONV => RELU) * 2 => POOL\n",
        "\t\t# layer set\n",
        "\t\tself.conv1A = Conv2D(outChannels, (3, 3), strides=1, padding=\"same\")\n",
        "\t\tself.act1A = Activation(\"relu\")\n",
        "\t\tself.bn1A = BatchNormalization(axis=chanDim)\n",
        "\t\tself.conv1B = Conv2D(outChannels*2, (3, 3), strides=2, padding=\"same\")\n",
        "\t\tself.act1B = Activation(\"relu\")\n",
        "\t\tself.bn1B = BatchNormalization(axis=chanDim)\n",
        "\t\tself.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
        "  \n",
        "\t\t# initialize the layers in the second (CONV => RELU) => POOL\n",
        "\t\t# layer set\n",
        "\t\tself.conv2A = Conv2D(outChannels*4, (3, 3), strides=2, padding=\"same\")\n",
        "\t\tself.act2A = Activation(\"relu\")\n",
        "\t\tself.bn2A = BatchNormalization(axis=chanDim)\n",
        "\t\tself.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
        "\n",
        "\t\t# initialize the layers in our fully-connected layer set\n",
        "\t\tself.flatten = GlobalAveragePooling2D()\n",
        "\t\tself.dense3 = Dense(512)\n",
        "\t\tself.act3 = Activation(\"relu\")\n",
        "\t\tself.bn3 = BatchNormalization()\n",
        "\t\tself.do3 = Dropout(0.5)\n",
        "\n",
        "\t\t# initialize the layers in the softmax classifier layer set\n",
        "\t\tself.dense4 = Dense(classes)\n",
        "\t\tself.softmax = Activation(\"softmax\")\n",
        "\n",
        "\tdef call(self, inputs):\n",
        "\t\t# build the first (CONV => RELU) * 2 => POOL layer set\n",
        "\t\tx = self.conv1A(inputs)\n",
        "\t\tx = self.act1A(x)\n",
        "\t\tx = self.bn1A(x)\n",
        "\t\tx = self.conv1B(x)\n",
        "\t\tx = self.act1B(x)\n",
        "\t\tx = self.bn1B(x)\n",
        "\t\tx = self.pool1(x)\n",
        "\t\n",
        "\t\t# build the second (CONV => RELU) => POOL\n",
        "\t\t# layer set\n",
        "\t\tx = self.conv2A(x)\n",
        "\t\tx = self.act2A(x)\n",
        "\t\tx = self.bn2A(x)\n",
        "\t\tx = self.pool2(x)\n",
        "\n",
        "\t\t# build our FC layer set\n",
        "\t\tx = self.flatten(x)\n",
        "\t\tx = self.dense3(x)\n",
        "\t\tx = self.act3(x)\n",
        "\t\tx = self.bn3(x)\n",
        "\t\tx = self.do3(x)\n",
        "\n",
        "\t\t# build the softmax classifier\n",
        "\t\tx = self.dense4(x)\n",
        "\t\tx = self.softmax(x)\n",
        "\n",
        "\t\t# return the constructed model\n",
        "\t\treturn x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xba9ade2o0g2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "b8deb99b-3b89-4558-e78d-b97935825107"
      },
      "source": [
        "mini_vgg_v2 = MiniVGGNetModel(len(LABELS), channels=1)\n",
        "for layer in mini_vgg_v2.layers:\n",
        "    print(layer.get_config())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 8, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_20', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'}\n",
            "{'name': 'batch_normalization_15', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
            "{'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_21', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'}\n",
            "{'name': 'batch_normalization_16', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
            "{'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
            "{'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_22', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'}\n",
            "{'name': 'batch_normalization_17', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
            "{'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
            "{'name': 'global_average_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}\n",
            "{'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_23', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'}\n",
            "{'name': 'batch_normalization_18', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
            "{'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
            "{'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 7, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "{'name': 'activation_24', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XopDpDTGJ9C4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "d5d109e5-0a86-4f35-d063-00b3427a1e4f"
      },
      "source": [
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-prog-channels\")\n",
        "mini_vgg_v2 = MiniVGGNetModel(len(LABELS), channels=1)\n",
        "mini_vgg_v2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "mini_vgg_v2.fit(train_aug.flow(trainX, trainY, batch_size=64),\n",
        "    steps_per_epoch=np.ceil(len(trainX)/64),\n",
        "    validation_data=val_aug.flow(valX, valY, batch_size=64), \n",
        "    validation_steps=np.ceil(len(valX)/64),\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS),\n",
        "               EarlyStopping(patience=5, restore_best_weights=True)])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 382.0 steps, validate for 68.0 steps\n",
            "Epoch 1/50\n",
            "379/382 [============================>.] - ETA: 0s - loss: 2.2010 - accuracy: 0.1981"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "382/382 [==============================] - 10s 27ms/step - loss: 2.1995 - accuracy: 0.1985 - val_loss: 1.8372 - val_accuracy: 0.2498\n",
            "Epoch 2/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.9048 - accuracy: 0.2380 - val_loss: 1.7660 - val_accuracy: 0.2826\n",
            "Epoch 3/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.8120 - accuracy: 0.2637 - val_loss: 1.7393 - val_accuracy: 0.2905\n",
            "Epoch 4/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7710 - accuracy: 0.2754 - val_loss: 1.7932 - val_accuracy: 0.2730\n",
            "Epoch 5/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7532 - accuracy: 0.2842 - val_loss: 1.7297 - val_accuracy: 0.2895\n",
            "Epoch 6/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.7405 - accuracy: 0.2907 - val_loss: 1.7265 - val_accuracy: 0.2884\n",
            "Epoch 7/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7329 - accuracy: 0.2937 - val_loss: 1.7738 - val_accuracy: 0.2858\n",
            "Epoch 8/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.7206 - accuracy: 0.3033 - val_loss: 1.7083 - val_accuracy: 0.3116\n",
            "Epoch 9/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7160 - accuracy: 0.3033 - val_loss: 1.6989 - val_accuracy: 0.3123\n",
            "Epoch 10/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.7049 - accuracy: 0.3114 - val_loss: 1.6915 - val_accuracy: 0.3209\n",
            "Epoch 11/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7043 - accuracy: 0.3103 - val_loss: 1.7196 - val_accuracy: 0.3051\n",
            "Epoch 12/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6991 - accuracy: 0.3186 - val_loss: 1.6933 - val_accuracy: 0.3181\n",
            "Epoch 13/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6933 - accuracy: 0.3196 - val_loss: 1.6592 - val_accuracy: 0.3415\n",
            "Epoch 14/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.6884 - accuracy: 0.3191 - val_loss: 1.7552 - val_accuracy: 0.3132\n",
            "Epoch 15/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6846 - accuracy: 0.3289 - val_loss: 1.6868 - val_accuracy: 0.3244\n",
            "Epoch 16/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6820 - accuracy: 0.3269 - val_loss: 1.6820 - val_accuracy: 0.3211\n",
            "Epoch 17/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6775 - accuracy: 0.3273 - val_loss: 1.7968 - val_accuracy: 0.3102\n",
            "Epoch 18/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6694 - accuracy: 0.3283 - val_loss: 1.6830 - val_accuracy: 0.3362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe067c0b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky46EJaZqCf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20c6e3cb-a326-41ea-baf1-368bdf788a2f"
      },
      "source": [
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-prog-channels-2\")\n",
        "mini_vgg_v2 = MiniVGGNetModel(len(LABELS), channels=1)\n",
        "mini_vgg_v2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "mini_vgg_v2.fit(train_aug.flow(trainX, trainY, batch_size=64),\n",
        "    steps_per_epoch=np.ceil(len(trainX)/64),\n",
        "    validation_data=val_aug.flow(valX, valY, batch_size=64), \n",
        "    validation_steps=np.ceil(len(valX)/64),\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS)])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-2\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-2</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 382.0 steps, validate for 68.0 steps\n",
            "Epoch 1/50\n",
            "381/382 [============================>.] - ETA: 0s - loss: 2.2321 - accuracy: 0.1911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "382/382 [==============================] - 10s 27ms/step - loss: 2.2315 - accuracy: 0.1912 - val_loss: 1.8486 - val_accuracy: 0.2524\n",
            "Epoch 2/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.9289 - accuracy: 0.2270 - val_loss: 1.7736 - val_accuracy: 0.2712\n",
            "Epoch 3/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.8328 - accuracy: 0.2515 - val_loss: 1.7635 - val_accuracy: 0.2751\n",
            "Epoch 4/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7921 - accuracy: 0.2659 - val_loss: 1.7527 - val_accuracy: 0.2740\n",
            "Epoch 5/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.7716 - accuracy: 0.2717 - val_loss: 1.7458 - val_accuracy: 0.2935\n",
            "Epoch 6/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7670 - accuracy: 0.2776 - val_loss: 1.7440 - val_accuracy: 0.2958\n",
            "Epoch 7/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.7487 - accuracy: 0.2876 - val_loss: 1.7169 - val_accuracy: 0.3037\n",
            "Epoch 8/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.7384 - accuracy: 0.2958 - val_loss: 1.7239 - val_accuracy: 0.2944\n",
            "Epoch 9/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7335 - accuracy: 0.2952 - val_loss: 1.7205 - val_accuracy: 0.3044\n",
            "Epoch 10/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7250 - accuracy: 0.3010 - val_loss: 1.7144 - val_accuracy: 0.3127\n",
            "Epoch 11/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7143 - accuracy: 0.3087 - val_loss: 1.6920 - val_accuracy: 0.3232\n",
            "Epoch 12/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.7088 - accuracy: 0.3103 - val_loss: 1.7220 - val_accuracy: 0.3011\n",
            "Epoch 13/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6974 - accuracy: 0.3182 - val_loss: 1.6778 - val_accuracy: 0.3316\n",
            "Epoch 14/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6958 - accuracy: 0.3176 - val_loss: 1.7107 - val_accuracy: 0.3271\n",
            "Epoch 15/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6918 - accuracy: 0.3208 - val_loss: 1.6968 - val_accuracy: 0.3213\n",
            "Epoch 16/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6812 - accuracy: 0.3247 - val_loss: 1.6708 - val_accuracy: 0.3327\n",
            "Epoch 17/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6790 - accuracy: 0.3319 - val_loss: 1.6500 - val_accuracy: 0.3453\n",
            "Epoch 18/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6686 - accuracy: 0.3375 - val_loss: 1.7142 - val_accuracy: 0.3218\n",
            "Epoch 19/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6647 - accuracy: 0.3339 - val_loss: 1.6451 - val_accuracy: 0.3353\n",
            "Epoch 20/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6649 - accuracy: 0.3375 - val_loss: 1.6728 - val_accuracy: 0.3357\n",
            "Epoch 21/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6520 - accuracy: 0.3449 - val_loss: 1.6997 - val_accuracy: 0.3262\n",
            "Epoch 22/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6579 - accuracy: 0.3412 - val_loss: 1.6418 - val_accuracy: 0.3462\n",
            "Epoch 23/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6420 - accuracy: 0.3454 - val_loss: 1.7906 - val_accuracy: 0.3278\n",
            "Epoch 24/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6445 - accuracy: 0.3535 - val_loss: 1.6365 - val_accuracy: 0.3511\n",
            "Epoch 25/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6393 - accuracy: 0.3503 - val_loss: 1.7188 - val_accuracy: 0.3025\n",
            "Epoch 26/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.6319 - accuracy: 0.3509 - val_loss: 1.8047 - val_accuracy: 0.2515\n",
            "Epoch 27/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6251 - accuracy: 0.3606 - val_loss: 1.6391 - val_accuracy: 0.3524\n",
            "Epoch 28/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6170 - accuracy: 0.3606 - val_loss: 1.6250 - val_accuracy: 0.3726\n",
            "Epoch 29/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6166 - accuracy: 0.3622 - val_loss: 1.5977 - val_accuracy: 0.3775\n",
            "Epoch 30/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6186 - accuracy: 0.3578 - val_loss: 1.7141 - val_accuracy: 0.2939\n",
            "Epoch 31/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6081 - accuracy: 0.3647 - val_loss: 1.6412 - val_accuracy: 0.3638\n",
            "Epoch 32/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6090 - accuracy: 0.3621 - val_loss: 1.6548 - val_accuracy: 0.3383\n",
            "Epoch 33/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.6053 - accuracy: 0.3701 - val_loss: 1.6262 - val_accuracy: 0.3738\n",
            "Epoch 34/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.6003 - accuracy: 0.3707 - val_loss: 1.6017 - val_accuracy: 0.3815\n",
            "Epoch 35/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.5915 - accuracy: 0.3726 - val_loss: 1.5761 - val_accuracy: 0.3764\n",
            "Epoch 36/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5922 - accuracy: 0.3720 - val_loss: 1.6323 - val_accuracy: 0.3722\n",
            "Epoch 37/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.5850 - accuracy: 0.3821 - val_loss: 1.6080 - val_accuracy: 0.3829\n",
            "Epoch 38/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5862 - accuracy: 0.3744 - val_loss: 1.6053 - val_accuracy: 0.3715\n",
            "Epoch 39/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.5815 - accuracy: 0.3772 - val_loss: 1.6075 - val_accuracy: 0.3840\n",
            "Epoch 40/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5802 - accuracy: 0.3811 - val_loss: 1.5570 - val_accuracy: 0.3926\n",
            "Epoch 41/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5811 - accuracy: 0.3794 - val_loss: 1.6024 - val_accuracy: 0.3782\n",
            "Epoch 42/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.5722 - accuracy: 0.3854 - val_loss: 1.6029 - val_accuracy: 0.3778\n",
            "Epoch 43/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.5714 - accuracy: 0.3842 - val_loss: 1.5531 - val_accuracy: 0.4093\n",
            "Epoch 44/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5673 - accuracy: 0.3855 - val_loss: 1.5608 - val_accuracy: 0.4031\n",
            "Epoch 45/50\n",
            "382/382 [==============================] - 9s 25ms/step - loss: 1.5662 - accuracy: 0.3851 - val_loss: 1.5512 - val_accuracy: 0.4079\n",
            "Epoch 46/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5605 - accuracy: 0.3928 - val_loss: 1.5602 - val_accuracy: 0.4003\n",
            "Epoch 47/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5599 - accuracy: 0.3907 - val_loss: 1.5226 - val_accuracy: 0.4124\n",
            "Epoch 48/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5608 - accuracy: 0.3952 - val_loss: 1.6825 - val_accuracy: 0.3378\n",
            "Epoch 49/50\n",
            "382/382 [==============================] - 10s 25ms/step - loss: 1.5655 - accuracy: 0.3867 - val_loss: 1.5382 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "382/382 [==============================] - 9s 24ms/step - loss: 1.5512 - accuracy: 0.3934 - val_loss: 1.5558 - val_accuracy: 0.4007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe06776ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRTPs9Q6vs7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2af1729-cd57-4dd0-a0b6-ae162a4ea35c"
      },
      "source": [
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-prog-channels-wo_da\")\n",
        "mini_vgg_v2 = MiniVGGNetModel(len(LABELS), channels=1)\n",
        "mini_vgg_v2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "mini_vgg_v2.fit(trainX, trainY, \n",
        "    batch_size=64,\n",
        "    validation_data=(valX, valY),\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS)])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-wo_da\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-wo_da</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24402 samples, validate on 4307 samples\n",
            "Epoch 1/50\n",
            "24192/24402 [============================>.] - ETA: 0s - loss: 2.1178 - accuracy: 0.2321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: ERROR Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24402/24402 [==============================] - 4s 155us/sample - loss: 2.1167 - accuracy: 0.2320 - val_loss: 1.8309 - val_accuracy: 0.2287\n",
            "Epoch 2/50\n",
            "24402/24402 [==============================] - 3s 110us/sample - loss: 1.7937 - accuracy: 0.3144 - val_loss: 1.7025 - val_accuracy: 0.3192\n",
            "Epoch 3/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.6844 - accuracy: 0.3448 - val_loss: 1.6760 - val_accuracy: 0.3360\n",
            "Epoch 4/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.6309 - accuracy: 0.3647 - val_loss: 1.6763 - val_accuracy: 0.3455\n",
            "Epoch 5/50\n",
            "24402/24402 [==============================] - 3s 116us/sample - loss: 1.5987 - accuracy: 0.3753 - val_loss: 1.6276 - val_accuracy: 0.3664\n",
            "Epoch 6/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.5752 - accuracy: 0.3836 - val_loss: 1.5963 - val_accuracy: 0.3771\n",
            "Epoch 7/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.5590 - accuracy: 0.3948 - val_loss: 1.6476 - val_accuracy: 0.3610\n",
            "Epoch 8/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.5396 - accuracy: 0.4051 - val_loss: 1.6544 - val_accuracy: 0.3622\n",
            "Epoch 9/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.5276 - accuracy: 0.4059 - val_loss: 1.7205 - val_accuracy: 0.3485\n",
            "Epoch 10/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.5103 - accuracy: 0.4118 - val_loss: 1.6386 - val_accuracy: 0.3629\n",
            "Epoch 11/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.4959 - accuracy: 0.4218 - val_loss: 1.8604 - val_accuracy: 0.3146\n",
            "Epoch 12/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.4892 - accuracy: 0.4215 - val_loss: 1.5852 - val_accuracy: 0.3787\n",
            "Epoch 13/50\n",
            "24402/24402 [==============================] - 3s 110us/sample - loss: 1.4792 - accuracy: 0.4320 - val_loss: 1.5299 - val_accuracy: 0.4007\n",
            "Epoch 14/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.4712 - accuracy: 0.4319 - val_loss: 1.5415 - val_accuracy: 0.3947\n",
            "Epoch 15/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.4577 - accuracy: 0.4381 - val_loss: 1.5358 - val_accuracy: 0.3912\n",
            "Epoch 16/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.4485 - accuracy: 0.4382 - val_loss: 1.5470 - val_accuracy: 0.4012\n",
            "Epoch 17/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.4417 - accuracy: 0.4450 - val_loss: 1.5525 - val_accuracy: 0.3891\n",
            "Epoch 18/50\n",
            "24402/24402 [==============================] - 3s 110us/sample - loss: 1.4325 - accuracy: 0.4462 - val_loss: 1.5894 - val_accuracy: 0.3887\n",
            "Epoch 19/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.4267 - accuracy: 0.4488 - val_loss: 1.6159 - val_accuracy: 0.3933\n",
            "Epoch 20/50\n",
            "24402/24402 [==============================] - 3s 110us/sample - loss: 1.4188 - accuracy: 0.4539 - val_loss: 1.6404 - val_accuracy: 0.3817\n",
            "Epoch 21/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.4117 - accuracy: 0.4563 - val_loss: 1.5034 - val_accuracy: 0.4191\n",
            "Epoch 22/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.4041 - accuracy: 0.4570 - val_loss: 1.5094 - val_accuracy: 0.4140\n",
            "Epoch 23/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.3965 - accuracy: 0.4616 - val_loss: 1.4893 - val_accuracy: 0.4200\n",
            "Epoch 24/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3889 - accuracy: 0.4657 - val_loss: 1.5484 - val_accuracy: 0.4068\n",
            "Epoch 25/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3861 - accuracy: 0.4675 - val_loss: 1.4750 - val_accuracy: 0.4291\n",
            "Epoch 26/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.3821 - accuracy: 0.4653 - val_loss: 1.5576 - val_accuracy: 0.4005\n",
            "Epoch 27/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3769 - accuracy: 0.4714 - val_loss: 1.6002 - val_accuracy: 0.4070\n",
            "Epoch 28/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.3696 - accuracy: 0.4737 - val_loss: 1.5103 - val_accuracy: 0.4219\n",
            "Epoch 29/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.3649 - accuracy: 0.4734 - val_loss: 1.4844 - val_accuracy: 0.4328\n",
            "Epoch 30/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.3580 - accuracy: 0.4763 - val_loss: 1.6406 - val_accuracy: 0.3831\n",
            "Epoch 31/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.3601 - accuracy: 0.4773 - val_loss: 1.5502 - val_accuracy: 0.4172\n",
            "Epoch 32/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.3509 - accuracy: 0.4848 - val_loss: 1.5985 - val_accuracy: 0.3866\n",
            "Epoch 33/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3504 - accuracy: 0.4783 - val_loss: 1.5054 - val_accuracy: 0.4226\n",
            "Epoch 34/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.3438 - accuracy: 0.4861 - val_loss: 1.4856 - val_accuracy: 0.4256\n",
            "Epoch 35/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.3357 - accuracy: 0.4818 - val_loss: 1.5722 - val_accuracy: 0.3870\n",
            "Epoch 36/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.3350 - accuracy: 0.4871 - val_loss: 1.4621 - val_accuracy: 0.4395\n",
            "Epoch 37/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.3339 - accuracy: 0.4867 - val_loss: 1.4957 - val_accuracy: 0.4346\n",
            "Epoch 38/50\n",
            "24402/24402 [==============================] - 3s 116us/sample - loss: 1.3248 - accuracy: 0.4898 - val_loss: 1.4943 - val_accuracy: 0.4309\n",
            "Epoch 39/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.3264 - accuracy: 0.4902 - val_loss: 1.5000 - val_accuracy: 0.4284\n",
            "Epoch 40/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.3193 - accuracy: 0.4907 - val_loss: 1.5160 - val_accuracy: 0.4195\n",
            "Epoch 41/50\n",
            "24402/24402 [==============================] - 3s 113us/sample - loss: 1.3183 - accuracy: 0.4898 - val_loss: 1.5014 - val_accuracy: 0.4367\n",
            "Epoch 42/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.3147 - accuracy: 0.4938 - val_loss: 1.4737 - val_accuracy: 0.4437\n",
            "Epoch 43/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.3125 - accuracy: 0.4952 - val_loss: 1.5548 - val_accuracy: 0.4195\n",
            "Epoch 44/50\n",
            "24402/24402 [==============================] - 3s 112us/sample - loss: 1.3051 - accuracy: 0.4969 - val_loss: 1.5288 - val_accuracy: 0.4107\n",
            "Epoch 45/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3049 - accuracy: 0.4993 - val_loss: 1.4590 - val_accuracy: 0.4490\n",
            "Epoch 46/50\n",
            "24402/24402 [==============================] - 3s 114us/sample - loss: 1.3004 - accuracy: 0.5011 - val_loss: 1.4643 - val_accuracy: 0.4481\n",
            "Epoch 47/50\n",
            "24402/24402 [==============================] - 3s 109us/sample - loss: 1.2971 - accuracy: 0.5025 - val_loss: 1.4724 - val_accuracy: 0.4414\n",
            "Epoch 48/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.2925 - accuracy: 0.5025 - val_loss: 1.4662 - val_accuracy: 0.4488\n",
            "Epoch 49/50\n",
            "24402/24402 [==============================] - 3s 110us/sample - loss: 1.2897 - accuracy: 0.5043 - val_loss: 1.5017 - val_accuracy: 0.4326\n",
            "Epoch 50/50\n",
            "24402/24402 [==============================] - 3s 111us/sample - loss: 1.2915 - accuracy: 0.5016 - val_loss: 1.4878 - val_accuracy: 0.4407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdfd028b208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHSLjYcB5sOp",
        "colab_type": "text"
      },
      "source": [
        "Let's try Layer-Wise Sequential Unit Variance (LSUV) to initialize our network. LSUV was introduced in a paper called [All you need is a good init](https://arxiv.org/pdf/1511.06422.pdf) by Mishkin et. al. I have referred the Keras implementation from here: https://github.com/suvojit-0x55aa/LSUV-Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mlrk9RGxp2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEhjdYVsxutu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_mini_vgg(channels=1, init_kernel_size=3, classes=7):\n",
        "    \n",
        "    # determine the number of channels to output in the first\n",
        "    # conv layer\n",
        "    outChannels = 2**math.floor(math.log2(channels*init_kernel_size*init_kernel_size))\n",
        "\n",
        "    mini_vgg_seq = Sequential()\n",
        "    \n",
        "    mini_vgg_seq.add(Conv2D(outChannels, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
        "        input_shape=(48, 48, channels)))\n",
        "    mini_vgg_seq.add(BatchNormalization(axis=-1))\n",
        "    mini_vgg_seq.add(Conv2D(outChannels*2, (3, 3), strides=2, padding=\"same\", activation=\"relu\"))\n",
        "    mini_vgg_seq.add(BatchNormalization(axis=-1))\n",
        "    mini_vgg_seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    mini_vgg_seq.add(Conv2D(outChannels*4, (3, 3), strides=2, padding=\"same\", activation=\"relu\"))\n",
        "    mini_vgg_seq.add(BatchNormalization(axis=-1))\n",
        "    mini_vgg_seq.add(Conv2D(outChannels*8, (3, 3), strides=2, padding=\"same\", activation=\"relu\"))\n",
        "    mini_vgg_seq.add(BatchNormalization(axis=-1))\n",
        "    mini_vgg_seq.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    mini_vgg_seq.add(GlobalAveragePooling2D())\n",
        "    mini_vgg_seq.add(Dense(512, activation=\"relu\"))\n",
        "    mini_vgg_seq.add(BatchNormalization())\n",
        "    mini_vgg_seq.add(Dropout(0.5))\n",
        "    mini_vgg_seq.add(Dense(classes, activation=\"softmax\"))\n",
        "    \n",
        "    return mini_vgg_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZWGKqoLw3kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/suvojit-0x55aa/LSUV-Keras/master/lib/lsuv.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrygJvjdw5ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lsuv import LSUVinitialize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R_AYcegxD8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6d233413-083a-485f-a294-33fd3537bcb4"
      },
      "source": [
        "mini_vgg_v2 = seq_mini_vgg(classes=len(LABELS))\n",
        "mini_vgg_v2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "mini_vgg_v2 = LSUVinitialize(mini_vgg_v2, trainX[:64,:,:,:])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init Layer conv2d_41\n",
            "0.27400485\n",
            "Init Layer conv2d_42\n",
            "0.3679965\n",
            "Init Layer conv2d_43\n",
            "0.13762803\n",
            "Init Layer conv2d_44\n",
            "0.14265084\n",
            "Init Layer dense_28\n",
            "0.3836396\n",
            "dense_29 too small\n",
            "LSUV: total layers initialized 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc5GG0sNxZf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c72eacc6-0918-4a4f-fb03-67cca20bc491"
      },
      "source": [
        "wandb.init(project=\"emotion-detection\", entity=\"sayakpaul\", id=\"mini-vgg-prog-channels-wda-lsuv\")\n",
        "mini_vgg_v2.fit(trainX, trainY, \n",
        "    batch_size=64,\n",
        "    validation_data=(valX, valY),\n",
        "    epochs=50,\n",
        "    class_weight=classWeight,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", validation_data=(valX, valY), labels=LABELS)])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-wda-lsuv\" target=\"_blank\">https://app.wandb.ai/sayakpaul/emotion-detection/runs/mini-vgg-prog-channels-wda-lsuv</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24402 samples, validate on 4307 samples\n",
            "Epoch 1/50\n",
            "24402/24402 [==============================] - 4s 172us/sample - loss: 2.4063 - accuracy: 0.2014 - val_loss: 1.7923 - val_accuracy: 0.2847\n",
            "Epoch 2/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.9124 - accuracy: 0.2701 - val_loss: 1.7389 - val_accuracy: 0.3097\n",
            "Epoch 3/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.7564 - accuracy: 0.3097 - val_loss: 1.6880 - val_accuracy: 0.3346\n",
            "Epoch 4/50\n",
            "24402/24402 [==============================] - 3s 118us/sample - loss: 1.6859 - accuracy: 0.3373 - val_loss: 1.6569 - val_accuracy: 0.3462\n",
            "Epoch 5/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.6473 - accuracy: 0.3538 - val_loss: 1.6410 - val_accuracy: 0.3511\n",
            "Epoch 6/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.6171 - accuracy: 0.3676 - val_loss: 1.6230 - val_accuracy: 0.3559\n",
            "Epoch 7/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.5992 - accuracy: 0.3755 - val_loss: 1.6062 - val_accuracy: 0.3692\n",
            "Epoch 8/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.5784 - accuracy: 0.3854 - val_loss: 1.5918 - val_accuracy: 0.3761\n",
            "Epoch 9/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.5597 - accuracy: 0.3914 - val_loss: 1.5791 - val_accuracy: 0.3778\n",
            "Epoch 10/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.5406 - accuracy: 0.4017 - val_loss: 1.5756 - val_accuracy: 0.3771\n",
            "Epoch 11/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.5317 - accuracy: 0.4056 - val_loss: 1.5661 - val_accuracy: 0.3761\n",
            "Epoch 12/50\n",
            "24402/24402 [==============================] - 3s 118us/sample - loss: 1.5103 - accuracy: 0.4135 - val_loss: 1.5615 - val_accuracy: 0.3870\n",
            "Epoch 13/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.4999 - accuracy: 0.4207 - val_loss: 1.5626 - val_accuracy: 0.3873\n",
            "Epoch 14/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.4860 - accuracy: 0.4231 - val_loss: 1.5456 - val_accuracy: 0.4068\n",
            "Epoch 15/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.4779 - accuracy: 0.4293 - val_loss: 1.5467 - val_accuracy: 0.3973\n",
            "Epoch 16/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.4619 - accuracy: 0.4357 - val_loss: 1.5561 - val_accuracy: 0.4028\n",
            "Epoch 17/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.4547 - accuracy: 0.4396 - val_loss: 1.5326 - val_accuracy: 0.4035\n",
            "Epoch 18/50\n",
            "24402/24402 [==============================] - 3s 116us/sample - loss: 1.4381 - accuracy: 0.4449 - val_loss: 1.5348 - val_accuracy: 0.4137\n",
            "Epoch 19/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.4326 - accuracy: 0.4449 - val_loss: 1.5330 - val_accuracy: 0.4061\n",
            "Epoch 20/50\n",
            "24402/24402 [==============================] - 3s 123us/sample - loss: 1.4232 - accuracy: 0.4527 - val_loss: 1.5284 - val_accuracy: 0.4038\n",
            "Epoch 21/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.4132 - accuracy: 0.4565 - val_loss: 1.5167 - val_accuracy: 0.4100\n",
            "Epoch 22/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.4018 - accuracy: 0.4614 - val_loss: 1.5185 - val_accuracy: 0.4163\n",
            "Epoch 23/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.3925 - accuracy: 0.4671 - val_loss: 1.5363 - val_accuracy: 0.4103\n",
            "Epoch 24/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.3831 - accuracy: 0.4697 - val_loss: 1.5178 - val_accuracy: 0.4142\n",
            "Epoch 25/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.3716 - accuracy: 0.4718 - val_loss: 1.5121 - val_accuracy: 0.4281\n",
            "Epoch 26/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.3600 - accuracy: 0.4799 - val_loss: 1.5085 - val_accuracy: 0.4205\n",
            "Epoch 27/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.3592 - accuracy: 0.4784 - val_loss: 1.5124 - val_accuracy: 0.4251\n",
            "Epoch 28/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.3556 - accuracy: 0.4777 - val_loss: 1.5114 - val_accuracy: 0.4298\n",
            "Epoch 29/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.3395 - accuracy: 0.4865 - val_loss: 1.5199 - val_accuracy: 0.4179\n",
            "Epoch 30/50\n",
            "24402/24402 [==============================] - 3s 118us/sample - loss: 1.3317 - accuracy: 0.4913 - val_loss: 1.5448 - val_accuracy: 0.4079\n",
            "Epoch 31/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.3238 - accuracy: 0.4957 - val_loss: 1.5035 - val_accuracy: 0.4312\n",
            "Epoch 32/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.3144 - accuracy: 0.4989 - val_loss: 1.5043 - val_accuracy: 0.4247\n",
            "Epoch 33/50\n",
            "24402/24402 [==============================] - 3s 118us/sample - loss: 1.3073 - accuracy: 0.4993 - val_loss: 1.4979 - val_accuracy: 0.4293\n",
            "Epoch 34/50\n",
            "24402/24402 [==============================] - 3s 116us/sample - loss: 1.3023 - accuracy: 0.5018 - val_loss: 1.5069 - val_accuracy: 0.4291\n",
            "Epoch 35/50\n",
            "24402/24402 [==============================] - 3s 115us/sample - loss: 1.2887 - accuracy: 0.5082 - val_loss: 1.5068 - val_accuracy: 0.4219\n",
            "Epoch 36/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.2804 - accuracy: 0.5110 - val_loss: 1.5120 - val_accuracy: 0.4247\n",
            "Epoch 37/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.2762 - accuracy: 0.5114 - val_loss: 1.5071 - val_accuracy: 0.4337\n",
            "Epoch 38/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.2649 - accuracy: 0.5169 - val_loss: 1.5042 - val_accuracy: 0.4363\n",
            "Epoch 39/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.2630 - accuracy: 0.5189 - val_loss: 1.5117 - val_accuracy: 0.4363\n",
            "Epoch 40/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.2568 - accuracy: 0.5199 - val_loss: 1.4998 - val_accuracy: 0.4377\n",
            "Epoch 41/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.2470 - accuracy: 0.5266 - val_loss: 1.5504 - val_accuracy: 0.4247\n",
            "Epoch 42/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.2362 - accuracy: 0.5283 - val_loss: 1.5026 - val_accuracy: 0.4344\n",
            "Epoch 43/50\n",
            "24402/24402 [==============================] - 3s 123us/sample - loss: 1.2277 - accuracy: 0.5317 - val_loss: 1.5371 - val_accuracy: 0.4263\n",
            "Epoch 44/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.2255 - accuracy: 0.5354 - val_loss: 1.5183 - val_accuracy: 0.4363\n",
            "Epoch 45/50\n",
            "24402/24402 [==============================] - 3s 119us/sample - loss: 1.2113 - accuracy: 0.5404 - val_loss: 1.6092 - val_accuracy: 0.4251\n",
            "Epoch 46/50\n",
            "24402/24402 [==============================] - 3s 121us/sample - loss: 1.2118 - accuracy: 0.5392 - val_loss: 1.5155 - val_accuracy: 0.4332\n",
            "Epoch 47/50\n",
            "24402/24402 [==============================] - 3s 123us/sample - loss: 1.1985 - accuracy: 0.5491 - val_loss: 1.5454 - val_accuracy: 0.4305\n",
            "Epoch 48/50\n",
            "24402/24402 [==============================] - 3s 124us/sample - loss: 1.1963 - accuracy: 0.5470 - val_loss: 1.5357 - val_accuracy: 0.4319\n",
            "Epoch 49/50\n",
            "24402/24402 [==============================] - 3s 120us/sample - loss: 1.1875 - accuracy: 0.5532 - val_loss: 1.5324 - val_accuracy: 0.4293\n",
            "Epoch 50/50\n",
            "24402/24402 [==============================] - 3s 117us/sample - loss: 1.1810 - accuracy: 0.5504 - val_loss: 1.5319 - val_accuracy: 0.4351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdfdbab6d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}